{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src='imgs/robotguy.png' alt=\"Smiley face\" width=\"42\" height=\"42\" align=\"left\">Learning Objectives\n",
    "* * *\n",
    "* Gain some high level knowledge around machine learning with a gentle/brief introduction\n",
    "* Learn the importance of pre-processing data and how `scikit-learn` expects data\n",
    "* See data transformations for machine learning in action\n",
    "* Get an idea of your options for learning on training sets and applying model for prediction\n",
    "* See what sort of metrics are commonly used in scikit-learn\n",
    "* Learn options for model evaluation\n",
    "* Become familiar with ways to make this process robust and simplified (pipelining and tuning parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments 3/28\n",
    "\n",
    "SOME overarching points:\n",
    "* Big goal:  make it as easy and painless to learn tensorflow\n",
    "* Motivate, draw audience in with pictures and maybe jump into EDA or learners (then talk about ML/sklearn etc); motivate through inline exercises or engaging audience with \"what next?\" questions\n",
    "* Have ML tips and best practices\n",
    "* Have sklearn tips and best practices\n",
    "\n",
    "data preprocessing very big so should mention, but really focus on learners; motivation by seeing some results immediately (Giri)\n",
    "Speaking - up in the air right now (Kim wouldn't mind handing it off to Giri and/or Jen)\n",
    "Introduce the math (Jen)\n",
    "\n",
    "Load data -> excercise -> math behind it -> model eval (for example) (Giri)\n",
    "External speakers (bring up Weds @ planning meeting) - perhaps Giri could reach out and find someone interested in doing a ML intro (fairly brief, though) (Micheleen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very brief introduction to machine learning\n",
    "\n",
    "Here's my hand-drawn diagram of the machine learning process:\n",
    "<img src='imgs/ml_process.png' alt=\"Smiley face\" width=\"550\">\n",
    "\n",
    "As far as algorithms for learning a model, I like to think of a couple ways to categorize machine learning approaches (with the help of the [machine learning wikipedia article](https://en.wikipedia.org/wiki/Machine_learning)).  The first way of thinking about ML, is by the type of information given to a system.  So, given that criteria there are three classical categories:\n",
    "1.  Supervised learning - we get the data and the labels\n",
    "2.  Unsupervised learning - only get the data (no labels)\n",
    "3.  Reinforcement learning - reward/penalty based information (feedback)\n",
    "\n",
    "Another way of categorizing ML approaches, is to think of the desired output:\n",
    "1.  Classification\n",
    "2.  Regression\n",
    "3.  Clustering\n",
    "4.  Density estimation\n",
    "5.  Dimensionality reduction\n",
    "\n",
    "--> This second approach is how scikit-learn categorizes it's ML algorithms...and you'll see how it works in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PRO TIP: Are you a statitician?  Want to talk like a machine learning expert?  Here you go (from the friendly people at SAS ([here](http://www.sas.com/it_it/insights/analytics/machine-learning.html))): \n",
    "\n",
    "A Statistician Would Say  | A Machine Learnest Would Say\n",
    "------------- | -------------\n",
    "dependent variable  | target\n",
    "variable  | feature\n",
    "transformation  | feature creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very brief introduction to scikit-learn (aka `sklearn`)\n",
    "\n",
    "This module is not meant to be a comprehensive introduction to ML, but rather an introduction to the current de facto tool for ML in python.  As a gentle intro, it is helpful to think of the `sklearn` approach having layers of abstraction.  This famous quote certainly applies:\n",
    "\n",
    "> Easy reading is damn hard writing, and vice versa. <br>\n",
    "--Nathaniel Hawthorne\n",
    "\n",
    "In `sklearn`, you'll find you have a common programming choice: to do things very explicitly, e.g. pre-process data one step at a time, perhaps do a transformation like PCA, split data into traning and test sets, define a classifier or learner with desired parameterss, train the classifier, use the classifier to predict on a test set and then analyze how good it did.  \n",
    "\n",
    "A different approach and something `sklearn` offers is to combine some or all of the steps above into a pipeline so to speak.  For instance, one could define a pipeline which does all of these steps at one time and perhaps even pits mutlple learners against one another or does some parameter tuning with a grid search (examples will be shown towards the end).  This is what is meant here by layers of abstraction.\n",
    "\n",
    "So, in this particular module, for the most part, we will try to be explicit regarding our process and give some useful tips on options for a more automated or pipelined approach.  Just note, once you've mastered the explicit approaches you might want to explore `sklearn`'s `GridSearchCV` and `Pipeline` classes.\n",
    "\n",
    "Here is `sklearn`'s algorithm diagram - (note, this is not an exhaustive list of model options offered in `sklearn`, but serves as a good algorithm guide).\n",
    "![](imgs/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning blurb from `sklearn` documentation (direct quote from [here](http://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html))\n",
    "\n",
    "#### The problem solved in supervised learning\n",
    "\n",
    "Supervised learning consists in learning the link between two datasets: the observed data X and an external variable y that we are trying to predict, usually called “target” or “labels”. Most often, y is a 1D array of length n_samples.\n",
    "\n",
    "All supervised estimators in scikit-learn implement a `fit(X, y)` method to fit the model and a `predict(X)` method that, given unlabeled observations X, returns the predicted labels y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning blurb from a different source (`sklearn`s was not general enough for this section)\n",
    "\n",
    "#### The problem solved in unsupervised learning\n",
    "In machine learning, the problem of unsupervised learning is that of trying to find <b>hidden structure</b> in unlabeled data. Since the training set given to the learner is unlabeled, there is no error or reward signal to evaluate a potential solution.  <br><br>--Unsupervised learning entry by the Quora community ([here](https://www.quora.com/topic/Unsupervised-Learning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some glossary terms (quoted directly from `sklearn` documentation) - you will find glossary terms dispersed throughout this module as well\n",
    "\n",
    "\n",
    "Training set and testing set<br>\n",
    "Machine learning is about learning some properties of a data set and applying them to new data. This is why a common practice in machine learning to evaluate an algorithm is to split the data at hand into two sets, one that we call the training set on which we learn data properties and one that we call the testing set on which we test these properties. (from [here](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction))\n",
    "\n",
    "Classification and regression (Supervised learning)<br>\n",
    "If the prediction task is to classify the observations in a set of finite labels, in other words to “name” the objects observed, the task is said to be a classification task. On the other hand, if the goal is to predict a continuous target variable, it is said to be a regression task.\n",
    "When doing classification in scikit-learn, y is a vector of integers or strings.\n",
    "Note: See the Introduction to machine learning with scikit-learn Tutorial for a quick run-through on the basic machine learning vocabulary used within scikit-learn. (from [here](http://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html))\n",
    "\n",
    "TODO: add more glossary terms (i.e. for unsupervised)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comments 3/28\n",
    "2 nbs: one w/ content+code, other one glossary (to switch back n forth) (Alain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocessing the Input Data\n",
    "\n",
    "#### `sklearn` needs data and features (aka columns with optional labels) in numpy arrays (aka ndarrays)\n",
    "\n",
    "<b>Commonly, machine learning algorithms will require your data to be standardized and preprocessed.  In `sklearn` the data must also take on a certain structure as well.</b>\n",
    "\n",
    "<p>What you might have to do before using a learner in `sklearn`:</p>\n",
    "1. Non-numerics transformed to numeric (tip: use applymap() method from `pandas`)\n",
    "* Fill in missing values\n",
    "* Standardization\n",
    "* Normalization\n",
    "* Encoding categorical features (e.g. one-hot encoding or dummy variables)\n",
    "\n",
    "<b>Features should end up in a numpy.ndarray (hence numeric) and labels in a list.</b>\n",
    "\n",
    "Data options:\n",
    "* Use pre-processed [datasets](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) from scikit-learn\n",
    "* [Create your own](http://scikit-learn.org/stable/datasets/index.html#sample-generators)\n",
    "* Read from a file\n",
    "\n",
    "If you use your own data or \"real-world\" data you will likely have to do some data wrangling and need to leverage `pandas` for some data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comments 3/28\n",
    "tips sections in pre-processing & quick refs (Giri, Micheleen)\n",
    "\n",
    "put glossary and extra content all at end (Micheleen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "Add some talking points about cross validation, why you want to do it, etc. (kendall)\n",
    "Add some description on what diabetes data set is. Show a few rows of the data, and explain what the columns are. Helps to visualize the data. \n",
    "\n",
    "What is train_test_split? What do you mean by manual? (Kim) SKLearn provides abstractions using \n",
    "\n",
    "When splitting into train, test, validation, do you get the three sets? (Kim) Answer: No, it's handled by SKLearn. You have more customized control (Micheleen)\n",
    "\n",
    "What is the score? (Kim) Each is a test run. Values are 0 to 1. Higher is better. (Micheleen)\n",
    "\n",
    "Maybe need a higher general-level ML overview, flow chart of steps? Preprocessing, data splitting, cross validation, etc in a flowchart. AI: Search for a flowchart online (CK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Dive In!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments 3/28\n",
    "\n",
    "ask the question/frame the question/write a program to answer this; need the data (talk about dataset); need the algorithms (talk about kmeans for e.g.)...did we answer our question correctly? then, eval model...(Giri)\n",
    "\n",
    "Best ML practices/tips throughout (Micheleen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>ML TIP:  Ask sharp questions.</b><br>e.g. What type of flower is this (pictured below) closest to of the three given classes?\n",
    "\n",
    "(This links out to source)\n",
    "<a href=\"http://www.madlantern.com/photography/wild-iris/\"><img border=\"0\" alt=\"iris species\" src=\"imgs/iris-setosa.jpg\" width=\"400\" height=\"400\"></a>\n",
    "\n",
    "### Labels (species names/classes):\n",
    "(This links out to source)\n",
    "<a href=\"http://articles.concreteinteractive.com/machine-learning-a-new-tool-for-humanity/\"><img border=\"0\" alt=\"iris species\" src=\"imgs/irises.png\" width=\"500\" height=\"500\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get to know the data - visualize and explore\n",
    "* Features (columns/measurements) come from this diagram (links out to source on kaggle):\n",
    "<a href=\"http://blog.kaggle.com/2015/04/22/scikit-learn-video-3-machine-learning-first-steps-with-the-iris-dataset/\"><img border=\"0\" alt=\"iris data features\" src=\"imgs/iris_petal_sepal.png\" width=\"200\" height=\"200\"></a>\n",
    "* Shape\n",
    "* Peek at data\n",
    "* Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments 3/28\n",
    "\n",
    "Time for presenting vs. time for exercises/practices (tradeoff) and how to mix; e.g. audience guesses what's next... (Alain)\n",
    "\n",
    "How would you like to learn? (Micheleen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Shape and representation<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# How many data points (rows) x how many features (columns)\n",
    "print(iris.data.shape)\n",
    "print(iris.target.shape)\n",
    "\n",
    "# What python object represents\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sneak a peek at data (a reminder of your `pandas` dataframe methods)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pandas df (adding real column names)\n",
    "iris.df = pd.DataFrame(iris.data, \n",
    "                       columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width'])\n",
    "\n",
    "\n",
    "# first few rows\n",
    "iris.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Describe the dataset with some summary statitsics<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summary stats\n",
    "iris.df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data ready - clean up\n",
    "* We don't have to do much with the `iris` dataset.  It has no missing values.  It's already in numpy arrays and has the correct shape for `sklearn`.  However we could try <b>standardization</b> and/or <b>normalization</b>. (later, in the transforms section, we will show one hot encoding, a preprocessing step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization - make our data look like a standard Gaussian distribution (commonly needed for `sklearn` learners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> FYI: you'll commonly see the data or feature set (ML word for data without it's labels) represented as a capital <b>X</b> and the targets or labels (if we have them) represented as a lowercase <b>y</b>.  This is because the data is a 2D array or list of lists and the targets are a 1D array or simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardization aka scaling\n",
    "from sklearn import preprocessing, datasets\n",
    "\n",
    "# make sure we have iris loaded\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# scale it to a gaussian distribution\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "# how does it look now\n",
    "pd.DataFrame(X_scaled).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's just confirm our standardization worked (mean is 0 w/ unit variance)\n",
    "pd.DataFrame(X_scaled).describe()\n",
    "\n",
    "# also could:\n",
    "#print(X_scaled.mean(axis = 0))\n",
    "#print(X_scaled.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PRO TIP: To save our standardization and reapply later (say to the test set or some new data), create a transformer object like so:\n",
    "```python\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# apply to a new dataset (e.g. test set):\n",
    "scaler.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization - scaling samples <i>individually</i> to have unit norm\n",
    "* This type of scaling is really important if doing some downstream transformations and learning (see sklearn docs [here](http://scikit-learn.org/stable/modules/preprocessing.html#normalization) for more) where similarity of pairs of samples is examined\n",
    "* A basic intro to normalization and the unit vector can be found [here](http://freetext.org/Introduction_to_Linear_Algebra/Basic_Vector_Operations/Normalization/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardization aka scaling\n",
    "from sklearn import preprocessing, datasets\n",
    "\n",
    "# make sure we have iris loaded\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# scale it to a gaussian distribution\n",
    "X_norm = preprocessing.normalize(X, norm='l1')\n",
    "\n",
    "# how does it look now\n",
    "pd.DataFrame(X_norm).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's just confirm our standardization worked (mean is 0 w/ unit variance)\n",
    "pd.DataFrame(X_norm).describe()\n",
    "\n",
    "# cumulative sum of normalized and original data:\n",
    "#print(pd.DataFrame(X_norm.cumsum().reshape(X.shape)).tail())\n",
    "#print(pd.DataFrame(X).cumsum().tail())\n",
    "\n",
    "# unit norm (convert to unit vectors) - all row sums should be 1 now\n",
    "X_norm.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PRO TIP: To save our normalization (like standardization above) and reapply later (say to the test set or some new data), create a transformer object like so:\n",
    "```python\n",
    "normalizer = preprocessing.Normalizer().fit(X_train)\n",
    "# apply to a new dataset (e.g. test set):\n",
    "normalizer.transform(X_test) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the learning easier or better  beforehand -  feature creation/selection\n",
    "* PCA\n",
    "* SelectKBest\n",
    "* One-Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis (aka PCA) reduces the dimensions of a dataset down to get the most out of the information without a really big feature space\n",
    "* Useful for very large feature space (e.g. say the botanist in charge of the iris dataset measured 100 more parts of the flower and thus there were 104 columns instead of 4)\n",
    "* More about PCA on wikipedia [here](https://en.wikipedia.org/wiki/Principal_component_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xcb3cd50>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4FNX6wPHvbN/ZTYMEktA7AlIFFAiEXhURC1hAuGK/\nFkBApclVAa/oT8GGF0EUkF5EpQqGJiBNpEmRFlooAZJN3X1/f2QNiUBIYJMNcD7PM8+zu3PmnHcW\n8s7smTNnNBFBURRFufUZ/B2AoiiKUjBUwlcURblNqISvKIpym1AJX1EU5TahEr6iKMptQiV8RVGU\n24RPEr6maRM0TTupadrvV1nfTNO0eE3TNnuXwb5oV1EURck9k4/qmQiMBSbnUCZGRO7zUXuKoihK\nHvnkDF9EVgPnrlFM80VbiqIoyvUpyD78ezRN26pp2g+aplUrwHYVRVEUfNelcy2bgNIi4tI0rT0w\nD6hcQG0riqIoFFDCF5GELK9/0jTtU03TiojI2X+W1TRNTe6jKIqSRyJyzW5zX3bpaFyln17TtOJZ\nXjcAtCsl+7+JSKFahg0b5vcYVEy3TkyFNS4V080bU2755Axf07SpQDRQVNO0w8AwwJKRu2U88KCm\nac8BaUAS8Igv2lUURVFyzycJX0Qevcb6T4BPfNGWoiiKcn3Unba5EB0d7e8QLqNiyp3CGBMUzrhU\nTLlTGGPKLS0v/T8FQdM0KWwxKYqiFGaapiEFfNFWURRFKcRUwlcURblNqISvKIpym1AJX1EU5Tah\nEr6iKMptQiV8RVGU24RK+EqhsWLFCkqUqIzFotOwYUtiY2P9HZKi3FLUOHylUDh8+DDVqtUjMXEy\n0ASj8X2qVPmJHTs2+Ds0RSn01Dh85aby66+/YjA0BdoDAbjdw9m7dxfx8fH+Dk1Rbhkq4SuFQtGi\nRRHZS8b8egAHAQ8Oh8N/QSnKLaagHoCiKDlq3rw5jRpVYM2aZqSlNcBkmsO7776H2Wz2d2gAbNmy\nhTVr1lC8eHG6dOmCyaT+dJSbj+rDVwoNt9vNrFmzOHr0KA0aNCAqKsrfIQEwZeoU+rzQB6kiGOOM\n1Ctfj58X/YzRaPR3aIoC5L4PXyV8RcmBiBAQEkBit0SIADzg/MbJNx98w/333+/v8BQFUBdtFcUn\n3G43rosuKOb9wACeUA9xcXF+jUtRrodK+IqSA5PJRN2GdTGtNEE6cAT4Exo3buzv0BQlz1TCV5Rr\nWDhnIXWlLoaRBkK+D2HKpClUq1bN32EpSp6pPnxFySURQdOu2U2qKAVO9eErio+pZK/c7FTCVxRF\nuU2ohK8oinKbUAlfURTlNuGThK9p2gRN005qmvZ7DmU+1jRtr6ZpWzVNq+2LdhVFUZTc89UZ/kSg\n7dVWaprWHqggIpWAZ4DPfdSuchPZsWMHI0aMoF69FtSv34qJE7/2d0iKclvxyQxQIrJa07QyORTp\nDEz2ll2vaVqQpmnFReSkL9pXCr9hw95h1KgPSE31AJ8BTl588VVEhN69n/RzdIpyeyioPvwSZNyj\n+LdY72fKbWDnzp3897/jSE1tD4wAugGdcLnG8vHHE/0cnaLcPgrlHK/Dhw/PfB0dHU10dLTfYlFu\n3MGDB7FYapKU5ASSs6xJUtMMK8p1WLlyJStXrszzdj6709bbpfO9iNS8wrrPgRUiMt37fjfQ7Epd\nOupO21vPoUOHqFbtLlyuccCLwCAgALt9ON999zn33XefnyNUlJubP+601bzLlSwAengDuxuIv1n7\n7xcuXEilyEiCdZ0H27fn3Llz/g6p0CtTpgwTJnyCzfYMNpuG2fwuzZrNZ968SSrZK0oB8skZvqZp\nU4FooChwEhgGWAARkfHeMuOAdkAi0EtENl+lrkJ7hv/HH3/QomFDZrhc1ADesFg4GRXF/GXL/B3a\nTSEpKYlTp04RGRlZaJ5kpSi3AvUAlHwwduxYdg4YwGfJGf3QiUBRk4mk1FQ1z4qiKH6jJk/LByEh\nIew1Gvn7cPQnEOxwqGSvKMpNQSX8PHjwwQdxVahAB13nNZOJDnY7Y8aO9XdYiqIouaK6dPIoOTmZ\nKVOmEBcXR/PmzWnYsKG/Q1IU5Tan+vAVJQcXLlwgJSWF0NBQ1SWn3PRUH76iXIHH4+Gpp14kNDSC\nkiUr0ahRa86fP+/vsBSlQKiEr9xWvvxyAtOm/UZa2jFSU8+weXMZnnuun7/DUpQCoRK+cltZtWoj\nLldPIAgwkpr6PL/++pu/w1KUAqESvnJbqVy5DDbbSsADgMGwgnLlcpro1b9WrVpFqfKlMFvN1L27\nLocOHfJ3SMpNTF20VXxu8+bNbNu2jXLlytGsWbNCdVE0MTGRxo3bcOBACpoWjMXyJ+vW/UzFihX9\nHVo2x44do2OXjmzduBV0oAMYzhkoe7Qse3fsxWBQ52rKJWqUjuIXY8d+xqBB/0HTWgG/8vjjHfn8\n8w/9HVY2qampxMTEkJKSQuPGjQkODvZ3SJepVb8Wf+h/4InyZEwmPgPoDbbJNv7a8xfh4eH+DlEp\nRFTCVwrcxYsXCQ2NJDX1d6AccAFdr86aNd9Tu3bBPtXy9OnT/PDDD2iaRseOHSlatGiBtn8jkpOT\ncQQ48LzhudTpOgcIB3OMmfgz8ei67s8QlUImtwlfTUau+MyZM2cwmYJJTS3n/SQQs7kqx48fL7CE\nHx8fz+LFi3n22ZdJTW2MpoHdPoTNm1dTqlSpAonhRlmtVixWC8lnkiEMcAPHwXrQylsj3lLJXrlu\nqiNQ8ZkSJUrgdJrIeMSxACtJT99KrVq1CqT9LVu2UK5cNZ54YhTx8eByhZCYOItz53oyaNBbBRKD\nL2iaxqdjP0WfpmNbbMP6tZWKoRX5ce6PDHxtoL/DU25i6gxf8Rmz2czy5d/TocNDxMY+Q0BAEWbO\nnEpkZGS+tHfo0CFGjHiPU6fO0bVrO95++wPi498DHgdcQBNgLm53XY4e3QLAqVOnePbZfvzxx25q\n1arGp5++T1hY2FXbSE5O5vDhw4SHhxMYGJgv+3ElvXr1okaNGqxbt46IiAgeeOABjEZjgbWv3JpU\nH76SL5KSkrDZbPk2QufEiRNUr34X58/3xO2ugq6PJiXlIG53LPD3Rdh+gBNd/5nBgzvTr99LVK/e\ngIMHW5Ge/iBm8wzKlVvJH3+sv+L8/GvXrqVDh6643XbS0s7w6acf07t3z3zZH0W5Ebntw0dECtWS\nEZKi5Oyjjz4Sq7WngHiX3WIwBIim/Z/3/WmBkmIwmOTpp1+S9PR02bx5swQE3CHg8ZbxiNNZWbZt\n23ZZ/ampqRIcHCGw0Ft2l9jtYbJ3714/7K2i5MybN6+ZX1UfvnJTSk9PR8Se5RM7NpuFiIhxOJ0V\nsVor0LfvE6SlpfDFFx9hNBqxWCy43YlAunebNDweFxaL5bL6T548SUqKAB29n1TFbK7Pjh078nfH\nFCUfqYSv3JS6dOmCxTIb+BRYjq4/yr/+1Yu//trBxo0LOXRoD2PGvJvtBqVq1arRsGFN7PYuwP+w\n27vQqFFdqlSpcln9YWFhaFoKsNH7yUnS07dQvnz5fN2vhIQEkpKS8rUN5falEr5yUypXrhyrVy+l\nVaul1Ko1ggEDOvLhh6OwWCxUrVqV4sWLX7aNpmn89NMsBg+O4qGH1jB0aDQ//DDzitcZrFYrU6ZM\nRNfbExTUHLu9Jq+99iJ33nlnvuxPUlISHe/vSEjREAKDA+n9dG/cbne+tKXcvtRFW+WWtmfPHr79\ndioGg4Ennngsz1MoxMbGsmvXLkqVKnXFXwK+8lLfl/hy2Zckd06GdNBn6rz94tu8+sqrmWU8Hg97\n9uzBYDDkayzKzUfNh+9jIsKY0aO5s0wZ6lSowNcTJ/o7JOUatmzZQr16TXj33STefvsideo0ynMf\nfIkSJWjVqlW+J9gVq1aQXDc5Y6C0DVw1Xfy8+ufM9WfPniWsRBjValWjao2qFC9dnISEhHyNSbn1\nqISfS5989BGTR4zgq8OH+b8DBxj24ovMnz/f32EpORg8eBSJicPweN7D43mfxMTXGD78vWxlXC4X\nM2bMYNKkSRw9ejRf48mpi6Zc6XIYj3rH2QtYjlmoUKZC5vpW7VtxNvAsDAQGwinTKTrc2yFf41Vu\nPSrh59Ksr7/mvy4X9YFmwBCXi9lff+3vsJQcxMdfBC5NpyBSmvj4S2fFFy5coHbtxvzrX+N58cUl\nVKtWj82bN/s8jlWrVlG8eDnMZgsVK9Zi165dl5X5eMzHFNlZhIAZAQRMC6BkfEmGvjk0c/2fB/6E\n+mT8AjADd8H2PdsB+P3332kQ1YCS5UvSvUd3Lly44PN9UG4NPkn4mqa10zRtt6Zpf2qadtm935qm\nNdM0LV7TtM3eZbAv2i1IusPBySzvj2saekCA3+JRru3xx+9H1wcDW4FN6PowHnusc+b6jz8ex+HD\n1UhIWEpi4lQuXhzFM8/092kMp06dokOHrpw69QkiqRw48AItWnQiLS0tW7myZcuyZ8ceJv1nEt/+\n91u2b95OkSJFMteHFgmF/d43AuyHiGIRnDhxgqgWUWwM2Uhsu1jm7pxL5wc7oyhXlJvB+jktZBw0\n9gFlyDj32ApU/UeZZsCCXNaXT7cmZJecnCwff/yx9HvpJfnuu+/E4/HkWD4mJkZCdV2GgwzQNAkL\nCJBdu3YVSKzK9fF4PDJy5H8lPLySRERUlg8++Cjbv/PTT/9b4IMsN29tk5CQSHnllf4ybtw4SUlJ\nueEYFi9eLEFBLbK0IeJwlJb9+/fnqZ7t27eL0W4UwhGKIWaHWfbt2yfTpk2TgFoBwnAyliGIyWKS\nxMTEzG1jYmLko48+kgULFlzz/7lycyKXN175IuHfDfyU5f0gYOA/yjQDvs9lffn3rXilp6dL60aN\npJ3dLiNBajocMuDll69aNi4uTtxut2zevFlee/VVef2119Qdl7eAmTNniq7fIXBUIEkMhjvFZKoi\n8K7Y7W2lceM2kp6enm0bj8cjmzZtkmXLlsnZs2ev2caWLVtE10sJXPQm/CNisQRIfHx8nuONi4uT\nkSNHyujRo+XcuXMiIjJ//nxxVnQKw7wJv39Gwk9NTRURkXdGviN6mC7We6ziKOmQR3s+qpL+Lagg\nE35XYHyW948DH/+jTDPgtPfs/wegWg715esXIyKyYsUKudPplHTvKddpEN1slgsXLmQrt2jRIinq\ndEqw1SolihSRX3/9Nd9jUwrW8OHviNlsF00ziaZZvVMyiEC6OJ01ZOXKlZll3W633H//o+JwlJOg\noKYSHBwhW7duvWYbvXo9Lw7HHWK39xFdLyWjRo3xWfzJyclSvU51sdayCm0QvYQuA98YKCIi58+f\nF4vdIvT1HgzeQBxhDtm0aZPP2lcKh9wm/IKaLXMTUFpEXJqmtQfmAZWvVnj48OGZr6Ojo4mOjvZp\nMAkJCUQYDPw992AIYDMYcLlcBHj75U+ePMnjXbsyLzGRJsC8lBS6tGvHgePHsdlsPo1H8Z9hw95g\nyJBBHDt2jIoVa5GSEuJdY8RgiMg29HH69OksXbqfxMSdgA2YTLduT7Fr18YrVZ1pwoRxPPLIEvbv\n30/t2k/SqFEjn8VvtVpZv2o9Y8eO5a/Df9GidwsefvhhIGMop0k3kRqYmlHYAqZQE3FxcT5rX/GP\nlStXsnLlyrxvmJujQk4LGV06i7K8v6xL5wrb/AUUucq6fDsK/u306dMSERwsn2ua/AnyitksjWrV\nyvZTd/ny5dI0KOhSxytIRadT9dvfojwej9SseY+Yza8K7BVN+0JCQiLl9OnTmWVGjBghmvZ6lv8S\np0TXQ/wYdc7S0tKkRNkSorXXhDcRuiPOEKecPHnS36EpPkYBTp62EaioaVoZTdMsQDdgQdYCmqYV\nz/K6ARl3+J71QdvXpWjRoixZtYrv6talbVgYsa1bM2/p0my32JcsWZLdqan8fS50ADiVlnbFW/aV\nm5+maSxbNp+WLY8QGtqaOnWmEhOzONujEWvXro2uzyOjdxIMhv9RtWr+TLXwT4cPH2b+/Pls2LAh\n19uYTCZ+XvwzVY9VxTDKQOS6SBZ9v4hixYrlY6RKoZabo8K1FqAdsAfYCwzyfvYM8LT39QvAH8AW\nYC3QMIe68vdQmAdvvfGGlNR1eSAgQIrb7fL5uHH+DknxIY/HIydPnsz1BVSPxyP9+r0hFkuAmM0R\nAk4xGm1Sr15TOXXqVL7FuXDhQtH1UAkM7CgOR1np3fuFPF94VRdqb23k8gxfzaVzDZs2bWLfvn1U\nr16dGjVq+DscxUfi4+Np164rW7duxuNJo2fPXnzxxUfZZte8munTp/PkkwNITo4BSmE29yM6+hBL\nlszxeZwiQlBQMS5enA80Ai7icNRj4cLxPr+2pdy81EPMfaRevXrUq1fP32EoPvbcc/3YsqU8qalL\ngASmTm1LgwZf0afPU9fc9o8/dpCc/CQZt55AWlo/1q+vn7ne4/EQFxdHSEjIFefazwuXy4XLdRG4\nx/tJAJpWn8OHD5OcnMyiRYtwuVy0aNGC8PDwG2pLufWpqRWUm8aMGTNp0qQjzZt3Zvny5TdU17p1\nG0lNfR4wAkG4XE+wevVvudq2VKmS6Po64O+5cdYSHl4CgG3bthERUYGyZasTHFyMGTNm3lCcDoeD\nEiXKARO8n/yJ272cypUrU/fuujwx4Ameee8ZqtSowu+//35DbSm3gdz0+xTkQiHqw1cKj6lTp4mu\nlxGYKTBZdL2Y/PLLL9ddX/Pm94rB8L53tE2SGI21pW7dxvLZZ5+L2+3OcduUlBS5++6WYjaXEigi\nmhYoAwe+Lm63W4oVKyvwrbferaLrYbJv377rjlNEZMeOHRIRUUHs9mJitTpl/PgJ8vY7b4u1tvXS\nDVf3Ig2bNryhdpSbF+oRhzdGRPi/99+nWe3adGjShDVr1vg7pNvaBx/8D5frY+BB4AlcriF88smk\n665v/PgPCAz8AJOpMVAajyeYzZsfpl+/b3n00X/luK3FYqFVq2YYDJHAWkSWMHbsNL755hsuXEgA\nHvOWrIXJdA/btm27rhh3797N9OnTuXDhAkeO7GHfvi3Ex8fRp09vDh05RErxFPi717ZExtz9ipIT\n1Yd/FaP+8x9mjh7Ney4Xx4D727Rh2dq11KpVK1s5j8fD+vXrOX/+PPXr1882jE/xnYwhs1mnF07H\nYLjmNarLbNy4kUOHDhEQEEBaWgrp6YGADZGlgAmX61/Mm1ea2NhYSpQocdV6Zs5cSErKGCBjnnyX\nawA//fQLkAr8DtQEzpOevpXSpYfkOc7Jk7/l2Wf7YjI1xePZxJNPdmXcuPcz1zdv2pwp30/BdacL\n7GDdYKVpk6Z5bke5zeTmZ0BBLhSSLp3KERGyJctNV4NB3hg4MFuZ9PR0eaBdO6nscEjLoCAJDwqS\nzZs3+yniW9vcuXPFbo8UmCjwieh6aJ6nunjppQGi66UlMPB+MZmCBR4QiBGon+VmKo/oemnZtm1b\njnU1aNAqS9eNiNE4QF544VWZOvU70fUwCQzsLLpeRl58sX+e9zUpKUms1gCBHd7640XXS8tvv/2W\nWcbj8cigNweJyWISo9koLdq1uGxqEOX2QUHNpePrpbAk/OqlSsnqLAn/VaNRhg4enK3MpEmTpInD\nISneMl+DNLjjDj9FfOv74YcfpEOHR6Rz58dk7dq1edp206ZN3knMznn/SbcLOLxz51QQeEfgdzEa\nXxVNCxCj0SoVK9a66qyWMTExouuhYjAMFJPpGQkJiZRDhw6JiMjevXtl1qxZsmHDhuvaz6NHj4rd\nXizbDJsBAR3kySeflJEjR8qePXsyy6alpYnL5bqudpRbh0r4N2jCl19KWV2XL0GGGwxSLDBQDhw4\nkK3MsKFDZXCWv8pjIGFOp58iVnIyd+5cCQzslC2JQoDACwLdRdNCxemMFIMhROBnAY9o2vtSqVLt\nq9b5+++/y9Chw+Wdd96Vo0eP+izW9PR0KVasjMA33jh/E3CI+U6zmO4xiSPYcd0HE+XWlNuEr268\nysHcOXOYN2UKzuBgXhk0iEqVKmVbv2DBAgY9+igxiYkUBd4yGvn17rtZtHq1fwK+DW3dupX58xfg\ncOj06NHjqtMG/PXXX9So0QCXazFQF5iK2fwibncRPJ4OWCyLady4LBs3hpGQ8K13K8FotHHhwjl0\nXS+oXQIyhne2bduFc+fO4vGk4a6YjHTzZKzcDE1dTfll6S8FGtPf3G43J06coEiRItjtdr/EoGSX\n2xuv/H5G/8+FQnKGnxsej0cGv/aa2E0mCdI0sWuatL7nHjlx4oS/Q7stLFu2TOz2UDEYBojF0kuK\nFSsjx48fv2r5mTNnid0eJFZriBQtGilWa6hAfGY/udkcKLpeTSDJ+9lm0fVgv01L4PF45PTp09Ll\n4S7CfVx6yElPpHq96n6JaceOHRJeKlzswXax2C3y+Ref+yUOJTtUl07+WbZsmbzy0ktSuWxZMRsM\n4gCZC3ISpL/JJFF16vg7xNtCjRqNBOZkdtGYTC/IG28MyXGbtLQ0OXXqlKxfv14CA2v9o5+8hrRs\n2UmczmridHYXXQ+TmTNnFdDeXN13330nerguPIvwEqJX0GX4iOF5quPQoUOyatWqPM2UuWvXLpk0\naZIsWrQo86BXumLpSweffyN6iJ6rZwIo+Usl/HzyxaefSmldl8EgnUAqgtyXJWu4Qewmk1y8eFHS\n0tIkOTnZ3yHfskqVqi6wOUvSfl+eeealXG2bkJAgRYuWEvifwHmBD8VsLioOR6gUL15WBg0aVKim\nwh46fKg4gh1iC7DJU888ddmTuHIy5sMxYgu0SVCFINGDdJk/f36O5detWycRZSIEC2KsbhRHSYfc\n1/U+uXDhghjNxks3ew1HnPWcMmnSpBvdPeUGqYSfT4o4HLLTm2E8IM1BykLm07MOgVgNBrmrenWx\nGAxiMRrlkXvvVSMp8sGrrw4SXW8psE9greh6SVm8eHGut9++fbtUqVJPzGZd7PbiYjY/I3BMIGN2\nSl89xtLtdsupU6cyHzuYV3v27JGg0CCx1reK9S6rBIUGyZ9//pnrbe3BduEVb5J+CnEEOrL9f8x6\nZ/GRI0fEEewQrAhPe7cZjDhLOeWHH36QgJAAobf389cRR4RDVqxYcV37pfhObhO+utM2DzweDwnJ\nyd4pszJuciwH2IEmwEBNo6HBQJgIKTt2EOvxcN7tJm3pUt7s189vcd+qRo8eQc+eNQkJiSYioief\nfPIObdq0yfX2NWrUYPfu30hMjCcl5QxpaR8DEUBHoOP1PVHoH7Zv305kZEVKlapCUFBYrubWmTNn\nDuWrlie8dDj/fvXfDBw8kIu1L5LSMYWUTilcrHWRN4e/mav29+/fjyXSAsHeD0oCFjhx4gSxsbHU\nu6ceZrOZ4NBg5syZQ0xMDJQG0oC/52Izgae4hxMnTjB9ynT02TqBswLR/6fTrXM3mjVrdh3fjOIX\nuTkqFORCIT/Df6BtW+lptcpBkAUggSDVjUaxa5qEm80SBtID5Mss3TxrQOpXruzv0JWr8Hg8YrMF\nCPyZefOV0xklM2bMyHNd8fHx8vjjT0v58nWkdev7JTS0pMDX3nq3iN0eetncOsnJyfJErydED9Ql\noGiAmHWz0APhBUSvrEtE2QjhkSwXbR9GmrZpmqt49u/fL/Ygu/DipQu+ASEBkpSUJLXq1xJjtFEY\nknHmrwfp8sknn4iznFOIRGhJRvfNs4g92C7bt28XEZHDhw/LggULZOPGjXn+fpT8gTrD972UlBRe\nfuMN4qOiaBwSwsCSJWnz4IOcMBr5S4QpaWlUAEoAWZ9LtEHTsNrtLFy4kPPnz/speuVqNE3j/fff\nQ9dbomlvousdqVRJ6Ny5c57qERHatevKjBlpHDjwOcuXN+D06XPA3/XUxmxudNncOi/3fZlZ62fh\n6uPi4oMXSTOkgQcIA1crFwkJCei/6nAO+BOMi424LrpYnYvhv+XLl+fjMR9jm2Qj4H8BOOc7mTtz\nLgaDge2bt+Nu6s6YMLQkUDnju6gaURWr3Qq/Af8B0yQT//v0f5nPgyhVqhT33nsvd911V56+H8X/\n1Dj8XIqNjaVN48Zw9izn3W4aNW/O1HnzmDlzJnOeeYaZFy9ykYwZVHoC04BigFPTWK1plLPZKGYy\nsc9mY+X69ZQtW9afu6NcwYoVK4iJWUV4eHF69uyZ54fVnzx5kjJl7iAlJY6MLApQD3gKeA64gMVS\njSFDnuXFF18kODijn6VE+RIca3cM/n565moggYznyO2DCpsr0LVzVz4e+zHJKckQBZjBvt7OvOnz\nctWNdebMGWJjYylXrhwBAQGICM5gJ67uroxeLDc4v3Ey5aMptG3blgkTJnA09ih31buLLl26ZHv8\np1L45HYcvkr4udS1bVuqL1/OW243qUBHXef+UaOIbt6c1g0bssblwgo8AazXNCJCQwkvXZrA0FAc\nK1YwIzUVDXjXaGRL69bM/Okn/+6Q4nPnzp2jePHSpKUdAwIADzZbLUSOYDZHk5CwDpMpBJutIg7H\nTrZsWUNERAQ16tZgR6UdUM1b0VzQjmmIWyAR6tauy6LvF9F3QF++PfptxgUjgO1wz5l7WLti7XXF\nO3XaVJ56/imoAsZTRhpWacjihYsxGo3X3lgpVHKb8FWXTi7t2rGDh9xuNMAK3OdysWvrVmrUqMHw\n996juslEFeAYECLCmTNnmLVwIWEOB+29yR4g2u3m8F9/+W0/lLz75ZdfiIyshMlkpXbtJhw8ePCK\n5UJCQnj00cfQ9fbAF9hsj1KlSiCbNq2hRo1zGAz3kZ6+m4SEhZw58xBvvPEfAMaOGYu+WMe8xIxt\nro1ip4thdpmhMfAMbDdup03HNriSXZD1R4cto5vxej3a/VHWrVzHmJ5jmDxmskr2t4PcdPQX5EIh\nvWjbtW1bGWw0igfkBEh5k0nqVaokQwcNkqSkJAkzm+V170XadJD2IFXKlZNxH30kTXRdLoCkgTxu\ntcoLvXv7e3eUXDp69Kg4HKECPwgkisEwUipUqHnVu2/dbreMG/epdO/+Lxk2bIQkJCSIiEjDhm28\ndfx9LX++kH7YAAAgAElEQVSmREffJ6NGvS8VKtSVihXrSY8ePWTcuHEyZcoUCaweeOki7VDE6rBm\n3IBVRBe6ITyB6OG6jB8/viC/DqWQQo3D962jR49K9bJlparTKUGaJj00TWaBdLbbpXPr1hICsj7L\nyJwvQCLsdnG73fJMz56im80SaLFI+6ZN5eLFi/7eHeUKUlNTZciQEdKoUXt57LGnJDY2VubMmfOP\nSdc8YrUWyfP0GUOGjBC7vZXABYFzoutR0r59Z9H12gJrBBaK3R4uP//8syxfvlycpZ3CUG/Cfw0x\nWU2SkJAgc+bMkdp315Ya9WrI559/7rdpH5TCRSX8fJCcnCxfffWV3OlwiMebAVJAQm02KWazydPe\nO21dII1Aalarlrnt+fPn5fTp0+oPtBB75JEnxW5vI7BATKZBEh5eXn788UdxOKoIJHsT/iExm3VJ\nSkrKU92pqany2GNPidFoEaPRIr17Py+VKt0lsCrLweQD6dXrOUlLS5N7mt0j9jvsQgvEUdIh/Qfk\nfV79/OR2u+Xw4cMSHx/v71AUyX3CV0+8ygOr1UrFihUxGy5d+jB4l4mzZ9O9UydmiZAK2K1WDqxf\nn1kuMDDwsvo2b95MTEwMYWFhPPTQQ1gslvzfCeWKkpKSmDVrGm73GcBBevq9JCZuITExkZYt67B8\neWPS0+/BaJzPiBHv5moET2pqKh99NJatW3dTt241Jk78lIkTP0XTNEwmE7VqNQXOZJbXtDPoug2T\nycTKJSv58ssv2f/Xfho914iuXbvm387n0dGjR2netjmxx2NxJ7vp27cvI98e6e+wlNzIzVHhWgsZ\nA8h2A38CA69S5mNgL7AVqJ1DXfl5ILxhSUlJUrNCBfm32Sw/gnSz2aRtkybi8XjE5XLJN998I/Pn\nz7/mXCczpk+XYna7vGC1SrTDIdH160tKSkoB7YXyTy6XS4xGq0BClsnU2sjs2bPF7XbL7Nmz5YMP\nPpCYmJhc1ed2u6VFi3vFbm8v8JnY7W2kXbsHsv3CW7hwofdBJ/8VTXtdAgKK5XrKBH+6p9k9Ymzu\nnVPntYzpFRYuXJi5/syZM7JhwwY1a2wBoqC6dMg4wd0HlAHM3oRe9R9l2gM/eF83BH7Nob78/WZ8\nIC4uTp7t2VNa1a8v/V98MfPCXF5EBAfLhiwTrjVzOGTq1Kn5EK2SW9269fL2s88Vk2mAREZWlPPn\nz19XXX/88Yc4HGUEUr0HkGSx2yMvS+gxMTHy9NP/lpdf7u+zuXvymyPIIfS/dOev1lSTt956S0RE\nFixYIHqgLoFlA8UWYJPxX6qLygUhtwnfF106DYC9InIIQNO078i4tXB3ljKdgcnebL5e07QgTdOK\ni8hJH7Rf4EJDQ/ls0qQcyyQnJ5OcnJx5c01WIsLpixep7n1vAKq53Zw+fdrnsSq5980343nnnfdY\nvnwC5cqVYPToVVfsivvb7t27OXv2LDVq1LisXHJyMgaDEzL/xCwYjY7LhlFGRUURFRXl4z3JX6XK\nlGL3gd0Zdxmmgx6rU65cORISEuj2eDdcD7sy7tw9Ay/3e5k2rdtQpkyZa1WrFABfjMMvARzJ8v6o\n97OcysReocwtQUQY9vrrhAQEUKpYMaLr1+fMmTPZymiaRqtGjRhkNpMI/ArMNhho2rSpX2JWMphM\nJoYNe4OYmO/5+uvPCQ8Pv2I5EaFXr+epW7cF7du/Qrly1fj999+zlalRowahoRom0xvAb5jNA4iI\ncFClSpUC2JP8NWXiFIJiggicHohjgoOm1Zvy6KOPEhsbi0E3ZCR7gKJgibCwb98+v8arXFIoL9oO\nHz4883V0dDTR0dF+iyWv5syZw6yxYzmUnk5R4OVt23jhySf57vvvs5WbPGcOPbt2pejatYQFBvLZ\n+PHUqlXLP0EreTJ//nxmzlxDUtKfJCU5ga956KFe7NmzKbOM1Wpl7dqlPP30q/zxRx9q1qzG+PGL\nMZvN/gvcKy0tje+//56JX09k45aNOAOcvDvsXR5++OFcbV+3bl327drHb7/9RnBwMA0bNkTTNEqU\nKIHH5ck45fOe4aceT6VixYr5uj+3o5UrV17fbK656ffJaQHuBhZleT+If1y4BT4HHsnyfjdQ/Cr1\n5U8nVwHp/8or8m6W8fh7QcqGhvo7LMWHRo8eLSZT3yzDKePFYnH4O6xcSUlJkbuj7hZLSYtwB4Id\noRWiF9Fl2bJlN1z/ggULRA9SffgFjQLsw98IVNQ0rQxwHOgGdP9HmQXAC8B0TdPuBuLlJu2/X7Zs\nGT8vXUpYeDh9+vTB6XRmW1+qXDmW2O14kpIwAKuAkiVuyd6r21aNGjWwWieRnj4YCEHTplCpUo08\n1zNr1mymTp1PkSKBvPFGX8qXL+/zWI8fP868efMA6NKlC4sWLWL7ye2k9k69NNziJ3Dd5WLazGm0\nbNnyhtq79957Obz/MPv376d06dJX7RZT/CQ3R4VrLWQMy9xDxrDLQd7PngGezlJmHBn/vbYBdXOo\nK1+PhDfi808+kdK6Lm+BPGizSZ3KlSUxMTFbmaSkJImuX1/qOZ3SKSBAigcGypYtW/wUsZIfPB6P\nvPLKQLFaQyQgoIoUL15Odu/enac6Pvnkc9H18gL/E4NhiAQFhcuhQ4d8Gue+ffskOCxY7PXsYq9r\nl+CwYOnfv7+YmpguTdswAMGKGJoYpG+/vj5tXyk45PIMX82WmQehAQHEJCRQDRCgvcPBo59+So8e\nPfB4PBw7doyAgAB0XWfFihUkJCTQuHFjihcvftU609PTeX/kSFb++CPFS5bkrf/+V02dfJM4duwY\nZ8+epWLFinmeSjkysgrHj39DxiA3MJleZNiwCAYPzt2TrHLjoUcfYs6pOXiiPAAYYgw0MzVj/ab1\nuB5xZUzouRLYB0FaENt+26ZG09ykcjtbZqG8aFsYiQgJycmU9r7XgNIeDwkJCcTGxtKpeXOOHT1K\nYno6/fr1462Rubvz8JVnn+WPadPo73KxxWgkasUKNu/aRVhYWL7ti+IbkZGRREZGXte26elpgCPz\nvcfjIC0t3UeRZTh+6jieMM+lNsI8pJ1Oo3LZymz9bCtooFk0nurxFIPfHEzp0qVzqE25FdzW0yPv\n2LGDTz/9lOnTp5OWlpZjWU3TuK9NG561WjkAzAfmahqtWrXiX488wn0HDnAiKYkDaWnMGDuWhQsX\nZts+OTmZ/wwdSreOHRn6+uu4XC48Hg8Tvv6aOS4XnYAhbjd3Jyfzww8/5Ns+K4VDnz490fVewM/A\nRGy2r3j44Qd92kbndp3R1+twAbgA+nodp9XJ1oNboT/wJkgFYenKpZcl+yNHjtD/tf489exTLF26\n1KdxKX6Um36fglwooD78+fPnS5iuSx+7XaJyObXBhQsX5MmHH5bSRYtKvcqVZcWKFSIiEup0yvEs\nI3Pe1DQZPmxY5nYej0c6NW8une12+RbkEZtNouvXl9TUVLGZTBKXZdsHHA6ZNGlSPu654ksej0f+\n859RUqLEHVK2bE2ZMGFirrZzu93y7rv/lTvvbCJRUR1k3bp1Po/N7XbLK/1fEZvDJnanXV7t/6rU\naVBHaJ/l+bjPIJpNy7bd0aNHJaRYiBgbGYW2GSN4vv32W5/Hp/gOarbMnJUJC5OYLFMbNHc4ZPLk\nyddV111Vq8o3WWbPvMdqlRZRUfL2iBFy4cIF2bt3r0Ta7ZKaZb78Sk6nbNq0SV557jlppOsyC+RN\no1FKh4XJ6dOnfby3Sn55//3/E12vI/CbQIzoehmZN2+ev8O6qo6dOgrVvA8nH47QATE5TdnKvPXW\nW2JqmOXC7pNImcpl/BOwkiu5Tfi3bZfOqfh4/r7NyQDcmZZGXFzcddX1xZQpvBYURJvAQKqazexP\nS+PeVavY9c47NLvrLhISEjAbDJlPOTUAFk3D7Xbz/tixPDh8ON80b86p7t1ZvWkTRYsW9cEeKgVh\n8uTZuFzvkfHs2ihcrsFMnjyH9HTf9sf7yueffY7poAnGA98AS6F9i/YkJydnlnEluUi3ZYnfTub6\n2NhYOnXpRIXqFXiw+4NqOpCbTW6OCgW5UEBn+B2bNZOXzGZJBtkCEq7rsmHDhuuuLy4uThYsWCAW\no1FivWfyHpBop1OmT58ujWvXlj4WiywGqWMwiE3TpHhgoHw0ZowP90opaI0btxeYnHkTlqb1FKs1\nRDTNIJUq1c7zcM2CcOzYManfoL4Y7AbhbkS/Q5faDWpndmlu3LhR9CBdeBjhKUSvoMtrg16TpKQk\nKV2xtBibGYU+iLmRWarVqiZpaWl+3iMF1aWTs7i4OGnbpImYDAYJCwiQKd98c8N1Jicni8VolOQs\nffIPOZ3yzTffyLlz5+S5J5+UckWLSgujUU6A7ASpqOsyZ84cH+yR4g8xMTGi66ECQ0XTnhbQBZYJ\npIumjZOSJStfc6rsgubxeMTmsAn/9nbZDEOcFZ0yc+bMzDJLliyR0pVKiy3YJmUrl5Xly5fL2rVr\nJaBMwKWunmGIo5ijUB7Ubje5Tfi3bZdOaGgoi1atIiUtjVMXLvDo44/fcJ1Wq5UOLVvS22olBugN\nLE5Pp3bt2gQHB/PpxIkEBQYy2u2mOHAH8JLLxZL582+4bcU/oqKiWL16Cf37p/Lgg/E4nVFAS8CI\nyAucOXOeEydOZNtm0aJF3HFHQ0qWvINXXx10zRFieSUiOXYpud1uUpNTIcj7gQaeEA/x8fGZZU6e\nOsnp+NMkt07m4B0HufeBe9mzZw+eZA+4vYXSwZ3ixmq1+jR+Jf/ctgn/bwaDb7+Cb2bPRuvUiU4G\nA8cMBlpoGh2aN+fgwYMAFClalF1Zyu82mymqbj+/qdWpU4f//nck/fv3Q+RPING75iBudwIhISGZ\nZTdt2sQDD/Rg9+7BxMZO54svNvLKK4OuWK/H42HYsLcpXboGlSvfxcyZs64Zy9hxY9GdOla7lejW\n0dmS+N9MJhNNoptgWWLJGLK5B/iTbJMUjhk7BldrF1QH6oDrbhdLVy6lbo262OfY4TfQZ+q0btn6\nlrpZa+/evXz//ffs3LnT36Hkj9z8DCjIhUI8tcKVxMXFyc6dO7M94/TpJ56QN4zGzG6dt4xG6fnQ\nQyIism7dOgl1OOQ5i0UettulfHi4nDp1yl/hKz7k8Xjk8cf7iNNZXXS9t+h6Cfnoo0+ylXnzzSGi\naW9mmXjtTwkNLXPF+t56613R9QbeEUBLxG6PuGyCs/T0dJk/f76MHz9evvzyS9HD9IyumsGIpYFF\nOnXpdMW6z549K+3vay/OEKeUrVJWfv7552zr69xdR+ieZfhmG+SJXk9IcnKyjBw1Urr36C4ffPjB\nLdV/P/7L8WIPsktgjUCxB9tl1Huj/B1SrqH68PPfmFGjJMhqlUoBAVKiSBHZvHmziIh0jo6WWVn6\n8ReCtL377szt9u7dKx9++KF89tlncvbsWX+Fr+QDj8cjixYtki+++OKKgwDefXekmM3/ypLwY6Ro\n0bJXPOhXqFBXYF22h5z/618vZK5PT0+XNm3uF6eznuh6LzGZgjNmwPw7Sb+KBBYNvK79mD59uuhF\ndaELQkdED9Jl/fr1udrW5XJJrz69JKJshNxZ705ZvXr1dcVQkM6cOZP9ukZfxBZokwMHDvg7tFxR\nCT+frV+/Xkrquhz1/jVOBakYGSkiImNGj5Ymui5nQM6BNNd1edf7CDjl9nby5EkpVqyMmEzPCowS\nKCJWax0JCYmUnTt3Zitbs2YTgbmZCd9gGCCvvPJa5vr58+eL01kvy2MUNwkGqzDUm7S6IeXvKH/d\nsc6bN0/adGoj93a9V9auXXvVcikpKXLs2DFxu90iItK1W1ex3WkTnkd4EHEEOwr94xu3b98uASWy\nXJAejgRVDJKVK1f6O7RcUQk/n02YMEF6OByZZ/EeELPBIImJibJ//37p1b27WE0msZpM8uyTT95S\nP32VvDt//rycOXNGPB6PHD9+XJo1ayEGQzXviB4RTRsrTZq0z7bNjz/+KLpeTOBtMRr7SlBQuPz1\n11+Z68ePHy+63ivLL4B0AYM4KjrEcZdDHEGOfE9YU6ZOEZvDJrZAmxQrUUy2bt0qZqtZGHgpcdoa\n2mTcuHH5GseNunjxogSEBAhPeON+KuNXzc3yIPbcJnw1edp1qlSpEu8A54AQYDHgtFgoFRLCxdRU\nTEB40aKs276diIgIv8aq+M/u3bt54onebNmyCYPBQlRUNAsWfEfZspX55ZcuZIzoAZHGHDkyPtu2\n7du3Z9myeXz33Wx03c6zz/6a7QLpPffcg8ibwGagFkbjf6hWrSFDhrzK+fPnad68ORUqVPDZvng8\nHvbu3Yvb7aZKlSrs37+fPs/1IblHMhSH5G3JtO3UFrPVTFpiGtgztjMkGtB13Wdx5Aen08n3c7/n\nvgfuI13SwQ3Tp0zPcabbm1JujgoFuXCTnOGLiAx69VUpZrNJTYNBdBALSAWQk97pGp4HuadmTX+H\nqfjJqlWrxGIJEnhCoL1ADbFaH5Bnn31FJk362jslw2mBVLFae8hjj/XJcxszZswUpzNUNM0oNWs2\nkiNHjuTDnmT0yzdp0UT0oro4ijmkdv3aMmnSJAmsFZitG8TqtMrb77wtejFdaI0YaxnFHmSXPs/2\nyfXZssfjyZd9yI2UlBQ5dOiQJCcn+y2G64Hq0ikY7aOj5SGjUU6BFAV5J8vF2v0gRa1Wf4eo+Em1\nag0FZmbpcnlU4BmpXr2ReDweefnlAWI0WsVkskvTpu3l/Pnz19WOx+OR1NRUH0ef3aA3B4mtpk0Y\ngjAUsda3Sqf7O4kjzCEMujQRm91pl7S0NFm4cKHUrl9bzMHmjPl6GpkkvFS4nDt37qpt/Prrr1Kq\nfCkxGA1S5c4qsmvXrnzdp1tJbhP+bT8O/0Yd3LuXIW43YUAosIJL96WsACwmE4P692fbtm1+i1Hx\nj9On44A7s3xyJ7CDChXKoGka//d/o0lIiOfs2ZP88suPBAYGXlc7mqb57OHobrebt999m9oNa9Oy\nfUu2bNkCwKZtm0iunAxGwAApVVOIPRHLk48+ie1LG7ZpNixTLHz15VeYTCY6dOjAzj92ktY7DRpA\nept0LoZcZP4/bjL89ddfeeCRB2jdqTXNWzfnyF1H8Azy8GfpP2nepjmpqak+2S8lg0r4N6hi5cos\n9N68NQVYT8YdtE2Bl4DWLhfWMWNo1agRa9asuWIdbreb06dP4/F4rrheuTm1bt0Sq3UIcBHYDXxM\ncPBexo4dlVnGZrMREBDgrxAvM/D1gYycMJJtVbbxs/FnolpEsW/fPmpVr4Vtnw08gIDlTws1q9ek\nyd1NkBTBLW5MRUx8NuEz0tPTERE8bg9kOQ6JSbLdVbx+/XpatmvJ3IS5LDMtIyk9KePJQmaQ+kJC\nSgKHDh0q8O/glpabnwEFuXCTdekcOHBAyoeHS4OAACltNEqo1So1qlSR2tWry8As3TsTQTo2bXrZ\n9t9//72E6LoEW61SOixMfvvtNz/shZIfEhISpHPn7mIy2cRmC5ann37umt02O3bskLFjx8q3336b\n7WY+Xzt16pTMmDFDFixYkK2dwKKBwkuX+uTNd5tl9OjRkpCQIPUb1RdHuEOckU65o9YdcubMmYyR\nLU97yw9FnOWdMnv2bBEReezJx8Re1S48iWjtNAksGiixsbGZbXV7opvQNst9Aw8jlPO+7o9Ydaua\nKjyXUKN0Cka5cuX4fd8+Nm3ahK7r1K1bF4PBwBNdulB5x47McpFA4sWLpKamMmzQIH7+8UcCg4P5\nbds2FiUn0xCYERfH/W3bcuD4cZ/9RFf8x+FwMG/eVEQETbvm40b56aef6Nq1ByJdMRr38t57n7B+\n/c95fl7utezatYvGzRqTHp6OJAmlHKVYv2o9AQEBmEwmyDINj5auYTKZcDgcrItZx/bt23G73dSs\nWRODwUDi+UT4eyCLATyhnsxpxr/64isih0Xy09KfiAiP4KNVH2V7JKRHPGTOGe7d3nDagHmxGdMB\nE30H9FVThftabo4KBblwk53hX82c2bOlrK5LDMhGkOpWq/zf++/LU489Ju3sdlkN8imIE+Rwll8C\nJXVdli1bJhs2bJDExER/74ZSgCIjK2eOyweP6Hp7GT9+vM/biWoVJVoHLXPGS2ttqwwbPkxEREa/\nN1r0CF24HzE0M0hIsZBsZ+X/VL9xfTFFmYTBGWPX7UF22b59e67i+OWXX8QebM+4m/dhRA/TpV+/\nfvLhhx9eNtWDkjPUKB3/69e3rwRrmoRrmpQzmyW6fn2xm81yNkuCfxhkjPf1bpAAg0Ei7HapHRgo\nZYsVkz179vh7N5QCoushAiczR/UYjQPknXfe8Xk7ZauUvdQNMzzjqVc9evcQkYwRP19P/lrue/A+\n6f1072w3el3J8ePHpWFUQzEYDRIcFpzZnZNbS5culei20dK4RWP57rvvrneXcrRr1y6ZPXu2bN26\nNV/qLwxUwi8EqpQoIYu8f71ukOZ2uzjMZjmUJeF3NJmkiMUiDwQESKDZLLWtVknwrhuraRJVp46/\nd0O5QStXrpQ+fV6UV199Tfbv33/Vcu3bPygWSx+BRIGtouuRsmbNGp/H06N3D7HWtWYMsRyAOEo7\n5KuvvspzPZO+niRFihcRq26V+x+6Xy5evOjzWG/U5198LvZguwTWDBS9iC7DRgzzd0j5okASPhk3\nmS4hY4LVxUDQVcodBLYBW4AN16gzX7+YghRkt8vpLMm9v9EobVu0kBoOh4wH+bfZLBUiImT58uUy\nffp0ef7552VwlvLHQMKcTn/vhnID5s+fL3Z7cYH/isEwUAIDi191Qq6zZ89Ky5b3idFokcDAYjJx\n4tf5EtOFCxekedvmYrKaxGQ2ycv9Xs7zzU6//PKL2IvYM34pDMjoFnrk8UfyJd7rdfbs2ewTovXP\n6HIq7PP6XI/cJvwbvWg7CFgmIu9pmjYQeN372T95gGgROXeD7d1Uoho25D9r1vB+WhoHgO+sVqYO\nH87BAwdY8eOPhJUowdpBgyhWrFjmNqO+/poBiYkEAN8ZDFSvUsVv8Ss37vXXR5KUNAHoiMcDCQnC\nuHGfM2bM6MvKhoSEsGzZfERyvsh79uxZNmzYgMPhoFGjRhiNxquWvZKAgAB+XvRzxrOWzebreoDJ\nkqVLSLozKWM0ApASncKSqUvyXE9+OnHiBOZAM8lFvc/rdYKluIUjR45QsWJF/wbnJzea8DsDzbyv\nvwZWcuWEr3Gbjfn3eDz8+/XX6fPYY0zwPui5fZs2NGnShKioKJ7o2fOybR566CFWLlpEhWnTCDOb\nSXE6WTx9ekGHrvhQUlIycGmkiccTSkLCkRy3ySnZ79y5kyZNWuN2V8XjOUGdOqVZtmw+Foslz7E5\nnc48b/O30KKh2M7ZSMabTOMgKCQo540KWNmyZTGkGTL6H6oARyD9VDrVqlXzd2j+k5ufAVdbgLM5\nvc/y+QEyZnjaCPS5Rp359KOn4KSkpEj7pk0l3GyWqiB/gGwDqeZwyKRc9JX+9ddfsnXr1nwdh60U\njBEjRoqu1/POa79A7PbiEhMTc9313XVXc9G0T729fmlit7fxy0yUFy5ckIp3VBS9hi6WeyxiD7LL\nTz/9VOBxXMvatWslJCxEbIE2cQQ55IcffvB3SPkCX3XpaJq2lEsjbSHjbF2AwVc6flylmsYiclzT\ntDBgqaZpu0Rk9dXaHD58eObr6OjobI9euxl8Mm4c2saN1ExL499kPCUOYEhiIrOmTaNnr145bl+2\nbNn8DlEpIG++OQBN05g48Xl03c4774wnKirquus7ePAvRFp735lISmrO3r1/+SbYPAgICGDLhi1M\nmzaNCxcu0OaLNtx5553X3rAA/PTTT/y0+CeKhxXnhRdeIO54HHFxcYSGhmbcZ3ALWLlyJStXrsz7\nhrk5KlxtAXYBxb2vw4FdudhmGNA3h/X5dRAsMM/37i0fgTwEMjbLRdh3NU16d+vm7/CUm1jbtl3F\nZOor4BE4Iw5HLZk6daq/w7qis2fPyoPdH5TIcpHSsGlD2bFjR763OXbc2IzHPLZCLHUtUqZiGblw\n4UK+t+tvFNDkaQuAJ72vewLz/1lA0zRd0zSn97UDaAP8cYPtFmo169dnhq7TFxgBPAc8Dfyf08mA\nLL9eFCWvJk/+lKpV12CzFcdsLk2vXq3o1q2bv8O6jIjQvnN7FuxfwLF2x9gQsIEm0U047b2elV/e\nHPomrodc0ARS70slzhbHjBkz8rXNm8mN/r4ZDczQNK03cAh4GEDTtAjgSxHpREZ30FxN08Tb3hQR\nKVyX832sz9NPsyEmhvazZyNpaXwlgmYw0P/556miRt0oN6BYsWL8/vs6jh8/jq7rBAcH+zukKzp3\n7hxbfttC6mupYAApLrgPulm9ejX3339/vrWbnJQMWeaiczvdJCYm5lt7N5sbOsMXkbMi0kpEqohI\nGxGJ935+3JvsEZG/RKS2iNQRkTtFZFTOtd7c0tPTeXvoUPbv2kWQrtPbYCAJ2OvxMHXsWJYsuaWP\ndUoB0DSNyMjIQpvsIWMWUI/bw9+DePCAJEq+P/nqvvvvw/ajDeKAHWDcZaRdu3b52ubN5LYaKlkQ\nXn7mGX758EMGb93Kufh4BrjdGIBSQPekJH5dt87fISpKvtN1nedffB59mg7rwDbXRsXiFfN9AMbk\nCZPpfnd3wheGU31fdRZ9v4jKlSvna5s3E+3/27vzuKrq9IHjn4dFNkVQCFAB9xrLrdz9lWhl0eRS\nvzIthZSa9Jel1cxUWprTbmVNWZOOS6WlpU2a22QblZlbpmKlmQaoaIsKCBoIPL8/uN5EQUGQc5Xn\n/XrxinO+33POcy/ep3O/57sUt/d7DhFRT4upvFSVID8/dh05Qj2gHTAOuJ7iRVF6BwZy84svkpSU\n5GicxlQHVeXNN9/ki5Vf0KxxM+666y4CAgKcDuucJCKo6imnZLWEX4VUleCAALbm5dEA+BKIBy71\n9SyNBqAAAB35SURBVGV7QQG/+viQNGIETzz33DnTPcwY47zyJnxr0qlCIsKou++mT2Ags4GFPj4E\nBgfzJTBMleQjR1g9bRr/GDvW6VCNMTWQ3eFXMVXl36++yqdLlhDesCGH8/Jo+frr/M1Vvh5IjIkh\nxZZuMyexbt06xox5kuzsHG65pR8jR44o1yIq5xpV5dUpr/Lm/DcJCQ7h8fGP07ZtW6fD8jjlvcO3\ndoUqJiL8ZcQI/jJiBAAPjxnDLm9vKCxe2nwXlZvDxJz7vvvuO+Li4snNfQxoRErKGA4ezGXMmL+d\n8thzzdPPPM2jLz7Kof85BNmQHJfM+tXr7UHsabI7/DMsIyODzm3acG1WFhEFBbwSEMAb//mPdRUz\nZRo79mGefLIA1Sdde74hKmogGRlbHY3LCVGxUeyN3wtRxdteH3rx0BUPMeGRCc4G5mHsDt9DNGjQ\ngDUpKUyfNo3Dubks+d//pWPHjk6HZTyYt7c3Iof5477nCF5eNfRx23EpTFSQ43eacrM7fA+QnZ3N\nmHvuYcOaNTS/4AKeeuklIiMjnQ7LOGT79u20a9eV3Nx7UW1EYOA/ePrpexg5coTToVW7Zyc9y/jn\nxnOo2yEkWwhaG8Q3a76psfPZl8W6ZZ4lVJXLu3QhZuNGhublsczHh/cbNuTr77+3Pss12Pfff88/\n/vEsWVk53HJLf265ZZDTITlCVZk5c6b7oe2EhyZw0UUXOR2Wx7GEf5ZIT0+n0wUXsPvwYY6uW9Qp\nOJhnFy3isssuczQ2Y6rT4sWLeWXaK9SqVYsH7n2ALl26OB3SWcP64Z8lfHx8KFDliGu7CDhcVGQD\ns0yNMn/+fG5KvIllsoyFuQu5/OrLWbt2rdNhnXPsDr+KFRYWsnHjRrZs2UKzZs3o2LHjSR+4qSoD\n+/Yl++OPueXwYf7r58dPF1xA8tq1+Pr6VmPkxjjnku6XsD5mPVzg2rESBjcYzKyZsxyN62xhvXQc\n8Ouvv3JF167s3r6dPCDA25tuvXoxf+nSMu/YRYTZ//kPkyZOZMlXX9GsVSteHTfOkr2pUbRIS7Y3\neEGRFjkWz7nK7vCr0C39+xO6cCEvAYeBq4G9vr78/ZVXuO222xyOzhjPNWv2LIbfO5xDPQ9BPgR8\nGsCHSz6ke/fuTod2VrA7fAds+uYbZlHcdTiQ4tVg3jpyhB3btjkbmDEebsjgIfj6+DJ52mT8avnx\n0HsPWbI/AyzhV6HmLVuyMD2ddkABsAxI9fWlfYcOFTrP119/zaZNm2jatCk9evQ4E6Ea43EGDhzo\nkcs1nkusSacKpaWl0bNzZ/x/+YUsVQ6KMGz4cJ5/+eVyT3w1+YUXeHLsWC4X4Sugb2Iiz7388pkN\n3BhzVrN++A7Jzc1l7dq1ZGdn07VrV8LDw8t9bFZWFtEREaTk5RELZAEXBgaybNUqWrdufcZiNsac\n3awN3yFBQUGnvYzbb7/9Rj0fH2Lz8gCoC5zv68uePXss4RtjKs0GXnmQmJgYCAzkDUCBT4CUwkLa\ntGnjcGTGmHOBJXwP4uvry/sffcQTjRrh5+XF4NBQ5i5caBOpGWOqhLXhe6jDhw/j7+9fI1c5MsZU\nTLXMpSMiN4jIZhEpFJGLT1LvahHZIiI/iMj9lblmTREQEGDJ3hhTpSr70DYFuA6YUlYFEfECJgOX\nAxnAWhFZqKpbKnltY8wZ0LhxY9JszWWPFBsbS2pq6mkfX6mEr6pbAeTkt6KdgG2qmuaqOxfoB1jC\nN8YDpaWlYc2qnqmy3/qr46FtQ2DnMdu7XPuMMcZUo1Pe4YvIh0DEsbso7jU4VlUXnYmgHnnkEffv\ncXFxp92v3RhjzkXJyckkJydX+Lgq6aUjIp8C96nq+lLKugCPqOrVru0HAFXVp8s4l/XSMcZBrh4f\nTodhSlHW38aJFa/KuthaoLmIxIpILWAg8H4VXtcYY0w5VLZbZn8R2Ql0ARaLyDLX/igRWQygqoXA\nSGA58C0wV1W/r1zYnu/nn39myZIlrFy50u6WjKkmI0aM4PHHH6+W4yt7LSfYwKszYPXq1fS98kra\nifBTYSEX9+rFWwsWnHSpQ2M8hSc36cTHx9O5c+cSz/kAFi5cyPDhw8nIyDinx694UpOOcbl90CBe\nPniQD7KzScnNJfWTT3jnnXecDsuYM27RokXEtIghJDyEQQmDyM3NrdLzJyYmMnv27BP2z549myFD\nhpw02RcWFlZpLGcjS/hnwE8ZGVzh+t0P+J+8vEoNljDGExw5coTR942mQZMGtGzdkiVLlpQoX79+\nPQMTBrKz206yBmexYOMCht0x7ITzbNu2jXnz5rFq1aoKx9C/f3/27dvHihUr3PsyMzNZvHgxQ4YM\nYejQoYwbNw6Azz77jOjoaCZOnEhUVBTDhhXHMnHiRBo0aECjRo2YPn06Xl5e7NixA6DU4ydNmkRE\nRAQNGzbktddec1/32LpQ/C2jffv21K1blxYtWrB8+XIAXnvtNVq1akVwcDDNmzdn6tSpFX7dVcUS\n/hnQoXVrXvHyQoE9wAI/Py655BKnwzKmUu79+71MXTyVPfF72NZmGwMGD2DNmjXu8g8++IC8C/Og\nKRACv1/5O0sWl/yfwty359KuUztue/w2ruh3BcNHDq9QDP7+/tx444288cYb7n1vv/02f/rTn0qd\nQnzv3r1kZmaSnp7O1KlT+e9//8sLL7zAJ598wo8//khycvJJvxXs3buXgwcPkpGRwbRp07jzzjvJ\nyso6od6aNWtITEzkueeeIysri88//5zGjRsDEBERwdKlS8nOzmbmzJncc889bNiwoUKvu6pYwj8D\nXps/n7mNGxMVEEALX1+S/vY3rrzySqfDMqZS3p73Nod7Hy4eldMSDrc9zHsL3nOXBwcHUyu71h8H\nZELtOrXdm0eOHGFo0lAODTxE9nXZ5A7LZfa82axevbpCcSQmJjJv3jzy8/MBmDVrFrfeemupdb29\nvZkwYQK+vr74+fkxb948hg4dygUXXIC/v/8JzwKOV6tWLR5++GG8vb2Jj4+ndu3abN269YR6M2bM\nICkpiV69egEQFRVFy5YtgeLnDkeT/6WXXkrv3r354osvKvSaq4ol/Cr29ty53HLttQTWqsVfH3mE\nPfv28eD48U6HZUylBQYFwsE/tn0O+VCndh33dkJCApF5kfi/5498IgT8J4AXnnnBXZ6ZmYmKwtHZ\nvv3BO8qbnTuPHYh/at27dyc8PJwFCxawY8cO1q5dy80331xq3fDwcHx9fd3bGRkZREdHu7ejo6NP\n+oC6fv36JTpbBAYGkpOTc0K9nTt30qxZs1LPsWzZMrp27Ur9+vUJDQ1l2bJl/Pbbb6d8nWeCrXhV\nhd5//33+OmwYUw8fphYwfMIEwsPDSRw61OnQjKm0iY9OZOjwoRy6+BA+B30I2R1CUlKSu7xOnTps\nWLuBmTNncuDAAXo/2Ztu3bq5y8PCwggNDWXvN3uhPbAXCtIKaNeuXYVjGTJkCK+//jpbtmzhqquu\nIiwsrNR6xzfXREVFsWvXLvd2enp6lfTqiY6OZvv27Sfsz8/P54YbbmD27Nn069cPLy8vrrvuOsd6\nQVnCr0Jzpk7l0cOHiXdtP3voEP+aOtUSvjknDBgwgIiICN57/z3q1qnL/434PyIiIkrUCQ4OZtSo\nUaUeLyIsX7Kc3n/uzYGPDyAqTJ8+nebNm1c4loSEBB577DFSUlJ4/vnnK/QakpKSGDx4MDExMTz2\n2GMVvnZpkpKSuOqqq7j22muJi4tjz5495OTk0KBBA/Lz8wkLC8PLy4tly5axfPlyx5YstYRfhfwC\nAjhwzHYm4Ofv71Q4xlS5Hj160KNHj9M+vnXr1mSkZbBv3z5CQkLw8Tm9FBQbG0u3bt1ISUmhb9++\n5T7u6quv5u6776Znz554e3vz8MMPM2vWLPz8/Mp1fFnfBjp27MjMmTMZPXo0P/30E5GRkbz88su0\nbNmSF198kRtvvJH8/Hz69OlDv379yh1vVbOBV1Vo/fr19L70Uu45dIhawMSAAOYvW1apD4gx1c2T\nB15VtS1bttC6dWvy8vLOioGRlR14ZQm/im3cuJHpr7xCYUEBCX/5C507d3Y6JGMq5FxP+AsWLOCa\na64hNzeXW2+9FR8fH959912nwyoXS/jGmCp1rif8+Ph4vvrqK3x8fIiLi+Pll18+4VmEp7KEb4yp\nUud6wj+b2Vw6xhhjysUSvjHG1BCW8B1QWFjIpIkT6dezJ38ZMqTEQBBjjDlTrA3fAaOHD2fdrFnc\nc+gQ33h7M6tePb7ZsoV69eo5HZox1obvweyh7VmmqKiIID8/dhUUUN+17/qgIPq/8goJCQmOxmYM\nWML3ZPbQ9iyklHzjvcA+YMZ4mIsuuojPP/+8Uufo2bMnM2bMqKKIKs8SfjXz8vIiKSGB6wMDWQI8\n6u3Nan9//vznPzsdmjEeLz4+vtQpjRcuXEhUVBRFRUVVdq3Nmzdz2WWXVdn5PIElfAf8c8oUet9/\nPy916cKP113HF+vWlTnbnzFnk0WLFhETcyEhIQ0YNCip2pc4rMj0CJ685OEZi01VPeqnOCRjjFPK\n+gzm5+frqFF/16ioltqixSW6ePHiEuVff/21Bgaep/CRQpr6+9+oAwbcesJ5fvjhB33nnXf0q6++\nqnBshw8f1pCQEP3iiy/c+w4cOKD+/v6akpKieXl5et9992lMTIxGRkbqiBEj9Pfff1dV1eTkZG3U\nqJE+/fTTGhkZqQkJCfrbb7/ptddeqyEhIVqvXj297LLL3Odt3Lixfvzxx6qqWlhYqI8//rg2a9ZM\ng4ODtUOHDrpr1y5VVf3yyy+1Y8eOGhISop06ddKVK1e6zxEXF6fTp09XVdWioiJ99NFHNTY2ViMi\nIjQxMVGzsrJUVTU1NVVFRKdPn64xMTHao0ePUl9/WX8b1/5T59fyVKrOH0v4xjirrM/gyJF/1YCA\nXgqbFJZoYOB5unr1anf5E088od7e9ymo62ePBgXVL3GOOXPe1sDAcA0Ovk6DgproHXeMrnB8t99+\nu95+++3u7VdffVXbt2+vqqqjR4/Wfv36aWZmpubk5Gjfvn11zJgxqlqc8H18fPTBBx/U/Px8/f33\n3/XBBx/UESNGaGFhoRYUFOiKFSvc5z024U+cOFHbtGmj27ZtU1XVTZs26f79+3X//v0aGhqqb775\nphYWFuqcOXM0NDRU9+/fr6olE/706dO1RYsWmpqaqrm5uXr99dfrkCFDVPWPhJ+YmKiHDh1y/0/q\neJbwjTFVqqzPYHh4E4Ut7oQu8rA+8MBYd/nkyZM1IOD6YxL+So2IaOouz8/PV3//YIUNrvIsDQpq\noqtWrapQfCtWrNCQkBDNy8tTVdXu3bvrP//5T1VVDQoK0h07drjrrly5Ups0aaKqxQnfz89P8/Pz\n3eXjxo3T/v37648//njCdY5N+Oeff74uWrTohDqzZs3Szp07l9jXtWtXff3111W1ZMK//PLL9V//\n+pe73tatW9XX11cLCws1NTVVvby8NDU19aSvvbIJv1Jt+CJyg4hsFpFCEbn4JPVSRWSjiHwjImvK\nqmeM8VyBgUHAHve2j88e6tQJcm8nJCQQGbkVf/+bEHmIgIDreeGFJ9zlmZmZqHoDbV17gvH2bltl\nSxz++uuvHDp0iEsuuYR69epRr1494uPj2bdvn/vY45c8/Pvf/06zZs3o3bs3zZs35+mnny71mjt3\n7qRp06Yn7M/IyCA2NrbEvtjYWHbv3n3KurGxsRQUFPDzzz+79zVq1Kj8b8RpqOxD2xTgOuCzU9Qr\nAuJUtb2qdqrkNY0xDpg4cRyBgTcDT+LjM4KQkOUkJQ1zl9epU4cNG1by1FPdGDfOl48+epeBA29y\nlx9d4hBec+3ZSEHBl5Va4nD27NnuJQ7DwsIIDAzk22+/Zf/+/ezfv5/MzEyysrLcxx2/gElQUBDP\nPvss27dv5/3332fSpEl8+umnJ1yvrCUMGzRoQGpqaol96enpNGzYsNS6aWlp7u20tDR8fX1LzNRZ\nFcstnlR5vgac6gf4FLj4JOU/AfXLea6TfqUxxpxZJ/sMJicn66hRf9Vx4x7RvXv3VvjcmzZt0sjI\npurnF6L+/sE6Z87bpxVjamqq1qpVS6Ojo3X+/Pnu/aNHj9YBAwboL7/8oqqqu3bt0g8++MAde3R0\ndInzLF682N2ck56erg0aNNDPPvtMVUs26TzzzDPatm3bE9rw9+3bp6GhoTpnzhwtKCjQuXPnltmG\nP23aNG3ZsqX+9NNPevDgQb3hhhs0ISHB/XpERAsLC0/6usv621CdbfjlSPg7gPXAWuD2U5zrpC/Y\nGHNmnenPYFFRkf7666965MiRSp0nLi5O69evX6JNPi8vT8eMGaNNmzbVunXraqtWrfSll15S1dIT\n/vPPP6+NGzfW2rVra3R0tD7++OPusiZNmpzQS6dJkyYaHBysnTp10t27d6tqcS+dSy65RENCQrRD\nhw4leun07NnzhF460dHRet5552lCQoJmZmaqqrrb8M90wj/l1Aoi8iFw7OoAQvFg0bGqushV51Pg\nPlVdX8Y5olR1j4iEAx8CI1V1RRl1dfz48e7tuLg44uLiThqjMabq2NQKnuvo3yY5OZnk5GT3/gkT\nJqDVNZfOqRL+cXXHAwdVdVIZ5Wr/2IxxjiV8z+VJc+mUejERCRSR2q7fg4DewOYqvK4xxphyqGy3\nzP4ishPoAiwWkWWu/VEisthVLQJYISLfAKuARaq6vDLXNcYYU3E2PbIxpgRr0vFcntSkY4wxxoNZ\nwjfGmBrCEr4xxtQQlvCNMaaGsIRvjDE1hCV8Y8xZZ8WKFXTv3p2QkBDCwsK49NJL+frrr095nJeX\nFzt27KiGCD2TJXxjTJVZtGgRF8bE0CAkhKRBg6p8iUOAgwcP0qdPH0aNGsWBAwfYvXs348ePx8/P\n75THnvHZKD2cJXxjTLkcOXKE+0eP5vwGDejQsiVLliwpUb5+/XpuGziQF3fuZFVWFgcXLGDksGEn\nnGfbtm3MmzePVatWnVYcP/zwAyLCgAEDEBH8/Py44ooruOiiiwCYMWMGrVq1on79+sTHx7vn2+/R\noweqSps2bQgODmbevHkA/Pvf/6ZFixaEhYXRv39/9uz5Y87/e+65h4iICOrWrUvbtm357rvvAFi6\ndCkXX3wxdevWJTY2lgkTJpzWa6l25ZlhrTp/sNkyjXFUWZ/Bv44cqb0CAnQT6BLQ8wIDT1ji8D5v\nbz265NUe0PpBQSXO8facORoeGKjXBQdrk6AgHX3HHRWOLzs7W8PCwjQxMVGXLVumBw4ccJctWLBA\nW7RooVu3bnXPcNmtWzd3uYiUWBHr448/1rCwMN2wYYPm5+frXXfd5V7X9oMPPtAOHTpodna2qqpu\n2bLFPSX0Z599pps3b1ZV1ZSUFI2MjNSFCxdW+LVUVFl/G2yJQ2PM6SjrM9gkPFy3/LF+oT4somMf\neMBdPnnyZL0+IMBdvhK0aUSEuzw/P1+D/f11g6s8C7RJUFCFlzhULU6+Q4cO1ejoaPXx8dF+/frp\nzz//rPHx8Tpjxgx3vcLCQg0MDNT09HRVLU7427dvd5cnJSXp/fff797OycnRWrVqaVpamn7yySd6\n/vnn66pVq7SoqOik8YwePVrvvffeCr+OiqpswrcmHWNMuQQFBh6zwCHs8fEhqE4d93ZCQgJbIyO5\nyd+fh0S4PiCAJ154wV2emZmJt+oxCxxCW2/vCi9xCHD++eczY8YM0tPT+fbbb8nIyGD06NGkpaUx\natQo9xKH9evXR0RKXXIQTlx2MCgoiHr16rF792569uzJyJEjufPOO4mIiGD48OHk5OQAsGbNGnr1\n6sV5551HSEgIU6ZM4bfffqvw66hulvCNMeUybuJEbg4M5ElghI8Py0NCGJaU5C6vU6cOKzdsoNtT\nT+E7bhzvfvQRNw0c6C4/usTha67tjcCXBQWntcThsVq2bEliYiKbN28mJiaGKVOmuJc4PHDgADk5\nOXTp0qXUY49fdjA3N5d9+/a5lygcOXIk69at47vvvmPr1q0888wzANx8883079+f3bt3k5mZyR13\n3HFWzD9kCd8YUy43DhjAnKVL2T9qFJFjxrAmJaXEeqwAwcHBjBo1ivGPPEK3bt1KlIkIC5Yv59HI\nSEL9/LjM35/J06fTvHnzCsWxdetWJk2a5L5r37lzJ3PmzKFr164MHz6cJ554wv1wNSsri/nz57uP\njYyMLNEtc9CgQcycOZNNmzaRl5fHmDFj6Nq1KzExMaxbt441a9ZQUFBAQEAA/v7+eHt7A5CTk0No\naCi+vr6sWbOGt956q0KvwTHlafepzh+sDd8YR53pz2BllzjcvXu3DhgwQBs2bKi1a9fWRo0a6YgR\nI/TgwYOqqjp79mxt3bq11q1bV2NiYjQpKcl97JQpUzQqKkpDQ0N13rx57n3NmjXT+vXra58+fdxL\nF3788cfapk0brVOnjoaHh+vgwYM1NzdXVVXfffddjY2N1eDgYO3Tp4/eddddOmTIkMq8LeVS1t+G\nqlrisLrZ9MjGOMumR/ZcNj2yMcaYcrGEb4wxNYQlfGOMqSEs4RtjTA1hCd8YY2oIS/jGGFND+Dgd\ngDHGs8TGxtb4aYQ91bHTQJyOSvXDF5GJQB8gD9gODFXV7FLqXQ28QPE3iumq+vRJzmn98I0xpgKq\nqx/+cuBCVW0HbAMeLCUQL2AycBVwITBIRC6o5HWrVXJystMhnMBiKh9PjAk8My6LqXw8MabyqlTC\nV9WPVLXItbkKaFRKtU7ANlVNU9UjwFygX2WuW9088Q9sMZWPJ8YEnhmXxVQ+nhhTeVXlQ9thwLJS\n9jcEjp3/dJdrnzHGmGp0yoe2IvIhcOyUeAIoMFZVF7nqjAWOqOpZMmWcMcbUPJWePE1EbgVuB3qp\nal4p5V2AR1T1atf2AxTP7Fbqg1sRsSe2xhhTQeV5aFupbpmu3jd/Ay4rLdm7rAWai0gssAcYCAwq\n65zlCdoYY0zFVbYN/yWgNvChiKwXkVcARCRKRBYDqGohMJLiHj3fAnNV9ftKXtcYY0wFedx8+MYY\nY84Mj51aQUTuE5EiEanndCwAIvIPEdkoIt+IyH9FJNIDYpooIt+LyAYReVdEgj0gphtEZLOIFIrI\nxQ7HcrWIbBGRH0TkfidjOUpEpovIzyKyyelYAESkkYh8IiLfikiKiNztdEwAIuInIqtdn7cUERnv\ndExQPK7I1ZrxvtOxHCUiqcfkpjUnq+uRCV9EGgFXAmmnqluNJqpqW1VtDywBPOEf4CkHvjkgBbgO\n+MzJIDx4wN9MimPyFAXAvap6IdAVuNMT3ifXM8Gers9bOyBeRDo5HBbAKOA7p4M4ThEQp6rtVfWk\n75FHJnzgeYofBnsMVc05ZjOI4jfZUeUc+FatVHWrqm6juPuukzxywJ+qrgAOOB3HUaq6V1U3uH7P\nAb7HQ8bJqOoh169+FHcwcbT92XUjeg0wzck4SiGUM5d7XMIXkb7ATlVNcTqW44nIYyKSDtwMjHM6\nnuOUNfCtprIBfxUkIo0pvpte7WwkxVzNJ98Ae4EPVXWtwyEdvRH1tAefSnHHmbUicvvJKjoyW+ZJ\nBnM9BIyhuDnn2DKn4xqrqotU9SHgIVd78F3AI07H5KpTrQPfyhOTObuISG1gPjDquG+zjnF9e23v\neja1QERaqaojzSki8mfgZ1XdICJxOP8N9ljdVXWPiIRTnPi/d32TPIEjCV9Vryxtv4hcBDQGNkrx\n/KyNgK9FpJOq/uJUXKV4C1hKNST8U8XkGvh2DdDrTMdyVAXeJyftBmKO2W7k2meOIyI+FCf7Waq6\n0Ol4jqeq2SLyKXA1zrWfdwf6isg1QABQR0TeUNUEh+JxU9U9rv/+KiLvUdycWWrC96gmHVXdrKqR\nqtpUVZtQ/DW8fXUk+1MRkebHbPanuK3TUccMfOt7koFvTnLyLsg94E9EalE84M9TelYInnWHOAP4\nTlX/6XQgR4lImIjUdf0eQPG3/i1OxaOqY1Q1RlWbUvxv6RNPSPYiEuj6doaIBAG9gc1l1feohF8K\nxXM+GE+JyCYR2QBcQfHTeqeVOvDNSSLSX0R2Al2AxSLiyHMFTx3wJyJvASuBliKSLiJDHY6nO3AL\n0MvVrW+960bCaVHAp67P22rgA1Vd6nBMnigCWOF61rEKWKSqy8uqbAOvjDGmhvD0O3xjjDFVxBK+\nMcbUEJbwjTGmhrCEb4wxNYQlfGOMqSEs4RtjTA1hCd8YY2oIS/jGGFND/D9Tx3yk3HD4LgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xccf0c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCA for dimensionality reduction\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# perform principal component analysis\n",
    "pca = decomposition.PCA(n_components = 3)\n",
    "pca.fit(X)\n",
    "X_t = pca.transform(X)\n",
    "(X_t[:, 0])\n",
    "\n",
    "# import numpy and matplotlib for plotting (and set some stuff)\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# let's separate out data based on first two principle components\n",
    "x1, x2 = X_t[:, 0], X_t[:, 1]\n",
    "\n",
    "\n",
    "# please don't worry about details of the plotting below \n",
    "#  (will introduce in different module)\n",
    "#  (note: you can get the iris names below from iris.target_names, also in docs)\n",
    "\n",
    "s1 = ['r' if v == 0 else 'b' if v == 1 else 'g' for v in y]\n",
    "s2 = ['Setosa' if v == 0 else 'Versicolor' if v == 1 else 'Virginica' for v in y]\n",
    "classes = s2\n",
    "colors = s1\n",
    "for (i, cla) in enumerate(set(classes)):\n",
    "    xc = [p for (j, p) in enumerate(x1) if classes[j] == cla]\n",
    "    yc = [p for (j, p) in enumerate(x2) if classes[j] == cla]\n",
    "    cols = [c for (j, c) in enumerate(colors) if classes[j] == cla]\n",
    "    plt.scatter(xc, yc, c = cols, label = cla)\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE IDEA:  Normalize data then rerun PCA and plot.  What changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution to exercise idea\n",
    "...code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting k top scoring features (also dimensionality reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SelectKBest for selecting top-scoring features\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Do feature selection\n",
    "#  input is scoring function (here chi2) to get univariate p-values\n",
    "#  and number of top-scoring features (k) - here we get the top 2\n",
    "X_t = SelectKBest(chi2, k = 2).fit_transform(X, y)\n",
    "\n",
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note on scoring function selection in `SelectKBest` tranformations:</b>\n",
    "* For regression - f_regression\n",
    "* For classification - chi2, f_classif\n",
    "\n",
    "#### One Hot Encoding\n",
    "* It's an operation on feature labels - a method of dummying variable\n",
    "* Expands the feature space by nature of transform - later this can be processed further with a dimensionality reduction (the dummied variables are now their own features)\n",
    "* FYI:  One hot encoding variables is needed for python ML module `tenorflow`\n",
    "* The code cell below should help make this clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OneHotEncoder for dummying variables\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'index': range(1, 7),\n",
    "                    'state': ['WA', 'NY', 'CO', 'NY', 'CA', 'WA']})\n",
    "print(data)\n",
    "\n",
    "# We encode both our categorical variable and it's labels\n",
    "enc = OneHotEncoder()\n",
    "label_enc = LabelEncoder() # remember the labels here\n",
    "\n",
    "# Encode labels (can use for discrete numerical values as well)\n",
    "data_label_encoded = label_enc.fit_transform(data['state'])\n",
    "data['state'] = data_label_encoded\n",
    "\n",
    "# Encode and \"dummy\" variables\n",
    "data_feature_one_hot_encoded = enc.fit_transform(data[['state']])\n",
    "\n",
    "# Put into dataframe to look nicer and decode state dummy variables to original state values\n",
    "# TRY:  compare the original input data (look at row numbers) to one hot encoding results\n",
    "#   --> do they match??\n",
    "pd.DataFrame(data_feature_one_hot_encoded.toarray(), columns = label_enc.inverse_transform(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encoded labels as dummy variables\n",
    "print(data_label_encoded)\n",
    "\n",
    "# Decoded\n",
    "print(label_enc.inverse_transform(data_label_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE IDEA:  Use one hot encoding to \"recode\" the iris data's extra suprise column (we are going to add a categorical variable here to play with...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "a = pd.DataFrame(X, \n",
    "                columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width'])\n",
    "\n",
    "col5 = pd.DataFrame(np.random.randint(1, 4, size = len(y)))\n",
    "\n",
    "X_plus = pd.concat([a, col5], axis = 1)\n",
    "X_plus.head(20)\n",
    "\n",
    "# ...now one-hot-encode..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and Predictions\n",
    "\n",
    "#### Let's start with an example of supervised learning\n",
    "\n",
    ">  Reminder:  All supervised estimators in scikit-learn implement a fit(X, y) method to fit the model and a predict(X) method that, given unlabeled observations X, returns the predicted labels y. (direct quote from `sklearn` docs)\n",
    "\n",
    "* Using regression and classification to train on a dataset, create a model, and predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "Maybe move learning and predictions section to the top? Also should move the cheat-sheet to the top. (Kim)\n",
    "\n",
    "Having the picture of the handwriting dataset is really nice (Kim)\n",
    "\n",
    "Might want to have a short guide on Jupyter (what is Jupyter, notebooks, etc) -- (Kim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.\"\n",
    "\n",
    "> \"Different estimators are better suited for different types of data and different problems.\"\n",
    "\n",
    "<a href = \"http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\" style = \"float: right\">-Choosing the Right Estimator from sklearn docs</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>An estimator for recognizing a new iris from its measurements</b>\n",
    "\n",
    "> Or, in machine learning parlance, we <i>fit</i> an estimator on known samples of the iris measurements to <i>predict</i> the class to which an unseen iris belongs.\n",
    "\n",
    "Let's give it a try!  (We are actually going to hold out a small percentage of the `iris` dataset and check our predictions against the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# Let's load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# split data into training and test sets using the handy train_test_split func\n",
    "# in this split, we are \"holding out\" only one value and label (placed into X_test and y_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1)\n",
    "\n",
    "# Define an estimator instance (here, support vector classification)\n",
    "#   this just means giving our instance a name and setting the parameters\n",
    "clf = svm.SVC(gamma = 0.001, C = 100.)\n",
    "\n",
    "# We can now fit and predict with this object instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's fit the data to the SVC instance object\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's predict on our \"held out\" sample\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What was the label associated with this test sample? (\"held out\" sample's original label)\n",
    "#  fill in the blank below\n",
    "\n",
    "# how did our prediction do?\n",
    "print(\"Prediction: %d, Original label: %d\" % (res[0], ___))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can be explicit and use the `train_test_split` method in scikit-learn ( [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) ) as in (and as shown above for `iris` data):<p>\n",
    "\n",
    "```python\n",
    "# Create some data by hand and place 70% into a training set and the rest into a test set\n",
    "# Here we are using labeled features (X - feature data, y - labels) in our made-up data\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "Be more concise and\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, linear_model\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "clf = linear_model.LinearRegression()\n",
    "score = cross_validation.cross_val_score(clf, X, y)\n",
    "```\n",
    "\n",
    "<p>There is also a `cross_val_predict` method to create estimates rather than scores ( [cross_val_predict](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_predict.html) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's move on to an example of unsupervised learning\n",
    "\n",
    ">  Reminder:  In machine learning, the problem of unsupervised learning is that of trying to find hidden structure in unlabeled data. Since the training set given to the learner is unlabeled, there is no error or reward signal to evaluate a potential solution. Basically, we are just finding a way to represent the data and get as much information from it that we can.\n",
    "\n",
    "HEY!  Remember PCA from above?  PCA is actually considered unsupervised learning.  We just put it up there because it's a good way to visualize data at the beginning of the ML process.\n",
    "\n",
    "We are going to continue to use the `iris` dataset (however we won't be needed the targets or labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: explain Kmeans clustering of iris code below\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "# data\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X)\n",
    "\n",
    "# how do our original labels fit into the clusters we found?\n",
    "print(k_means.labels_[::10])\n",
    "print(y[::10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE IDEA:  Iterate over different number of clusters, n_clusters param, in Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some feedback cross-validation and metrics\n",
    "* <b>Confusion matrix</b> - visually inspect quality of a classifier's predictions (more [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)) - very useful to see if a particular class is problematic\n",
    "\n",
    "<b>Here, we will process some data, classify it with SVM (see [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) for more info), and view the quality of the classification with a confusion matrix.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Comments\n",
    "What are precision and recall? (Kendall)\n",
    "Why is it called a confusion matrix? \n",
    "Describe what iris data set is, what the labels are, irises are flowers. (Kim)\n",
    "Might want to show the numbers in addition to the heat map\n",
    "Also might want to show a Yes No (True Positives, False Positives) example. (David)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import model algorithm and data\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import splitter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# feature data (X) and labels (y)\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform the classification step and run a prediction on test set from above\n",
    "clf = svm.SVC(kernel = 'linear', C = 0.01)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a plotting function confusion matrices \n",
    "#  (from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title = 'The Confusion Matrix', cmap = plt.cm.YlOrRd):\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add feature labels to x and y axes\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers in confusion matrix:\n",
    "* on-diagonal - counts of points for which the predicted label is equal to the true label\n",
    "* off-diagonal - counts of mislabeled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# see the actual counts\n",
    "print(cm)\n",
    "\n",
    "# visually inpsect how the classifier did matching predictions to true labels\n",
    "plot_confusion_matrix(cm, iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Classification reports</b> - a text report with important classification metrics (e.g. precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "Precision is low variability. (Micheleen)\n",
    "Recall is TP / (TP + FN) is also called sensitivity. \n",
    "f1-score ??? 2x precision / (precision + recall)\n",
    "Might want to not include classification report, because we have to explain all the terms (Kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Using the test and prediction sets from above\n",
    "print(classification_report(y_test, y_pred, target_names = iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another example with some toy data\n",
    "\n",
    "y_test = ['cat', 'dog', 'mouse', 'mouse', 'cat', 'cat']\n",
    "y_pred = ['mouse', 'dog', 'cat', 'mouse', 'cat', 'mouse']\n",
    "\n",
    "# How did our predictor do?\n",
    "print(classification_report(y_test, y_pred, target_names = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE IDEA:  Normaize or standardize data and reclassify and show confusion matrix.\n",
    "* something like [this](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models and Under/Over-Fitting)\n",
    "* Over-fitting or under-fitting can be visualized as below and tuned as we will see later with `GridSearchCV` paramter tuning\n",
    "* A <b>validation curve</b> gives one an idea of the relationship of model complexity to model performance.\n",
    "* For this examination it would help to understand the idea of the [<b>bias-variance tradeoff</b>](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff).\n",
    "* A <b>learning curve</b> helps answer the question of if there is an added benefit to adding more training data to a model.  It is also a tool for investigating whether an estimator is more affected by variance error or bias error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Might want to gloss over the code and focus on the visual, since we might not have too much time to go over everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Let's run a prediction on some test data given a trained model\n",
    "\n",
    "# First, create some data\n",
    "X = np.sort(np.random.rand(20))\n",
    "func = lambda x: np.cos(1.5 * np.pi * x)\n",
    "y = np.array([func(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A plotting function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_fit(X_train, y_train, X_test, y_pred):\n",
    "    plt.plot(X_test, y_pred, label = \"Model\")\n",
    "    plt.plot(X_test, func(X_test), label = \"Function\")\n",
    "    plt.scatter(X_train, y_train,  label = \"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy reading...create and use a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Pipelining</b> (as an aside to this section)\n",
    "* `Pipeline(steps=[...])` - where steps can be a list of processes through which to put data or a dictionary which includes the parameters for each step as values\n",
    "* For example, here we do a transformation (SelectKBest) and a classification (SVC) all at once in a pipeline we set up\n",
    "\n",
    "```python\n",
    "# a feature selection instance\n",
    "selection = SelectKBest(chi2, k = 2)\n",
    "\n",
    "# classification instance\n",
    "clf = svm.SVC(kernel = 'linear')\n",
    "\n",
    "# make a pipeline\n",
    "pipeline = Pipeline([(\"feature selection\", selection), (\"classification\", clf)])\n",
    "\n",
    "# train the model\n",
    "pipeline.fit(X, y)\n",
    "```\n",
    "\n",
    "See a full example [here](http://scikit-learn.org/stable/auto_examples/feature_stacker.html)\n",
    "\n",
    "Note:  If you wish to perform <b>multiple transformations</b> in your pipeline try [FeatureUnion](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(degree = 1, include_bias = False)\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"polynomial_features\", poly),\n",
    "                         (\"linear_regression\", lm)])\n",
    "pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)\n",
    "\n",
    "y_pred = pipeline.predict(X_test[:, np.newaxis])\n",
    "\n",
    "plot_fit(X, y, X_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last, but not least, Searching Parameter Space with `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments \n",
    "Should remove this part for the Google workshop (Micheleen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "lm = LinearRegression()\n",
    "\n",
    "pipeline = Pipeline([(\"polynomial_features\", poly),\n",
    "                         (\"linear_regression\", lm)])\n",
    "\n",
    "param_grid = dict(polynomial_features__degree = list(range(1, 30, 2)),\n",
    "                  linear_regression__normalize = [False, True])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid)\n",
    "grid_search.fit(X[:, np.newaxis], y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some References\n",
    "* [The iris dataset and an intro to sklearn explained on the Kaggle blog](http://blog.kaggle.com/2015/04/22/scikit-learn-video-3-machine-learning-first-steps-with-the-iris-dataset/)\n",
    "* [A. Mueller's Conference Notebooks and Presentation](https://github.com/amueller/odscon-sf-2015)\n",
    "* [Katie Malone's real-world example set of notebooks for learning ML](https://github.com/cmmalone/malone_OpenDataSciCon)\n",
    "* [Jake VanDerplas's PyCon Scikit-learn youtube video](https://www.youtube.com/watch?v=L7R4HUQ-eQ0)\n",
    "* [Brandon Rohrer's webinar Data Science for the Rest of Us](https://channel9.msdn.com/blogs/Cloud-and-Enterprise-Premium/Data-Science-for-Rest-of-Us)\n",
    "\n",
    "### Some Datasets\n",
    "* [Machine learning datasets](http://mldata.org/)\n",
    "* [Make your own with sklearn](http://scikit-learn.org/stable/datasets/index.html#sample-generators)\n",
    "* [Kaggle datasets](https://www.kaggle.com/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
