{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithms - Supervised Learning\n",
    "\n",
    ">  Reminder:  All supervised estimators in scikit-learn implement a `fit(X, y)` method to fit the model and a `predict(X)` method that, given unlabeled observations X, returns the predicted labels y. (direct quote from `sklearn` docs)\n",
    "\n",
    "* Given that Iris is a fairly small, labeled dataset with relatively few features...what algorithm would you start with and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.\"\n",
    "\n",
    "> \"Different estimators are better suited for different types of data and different problems.\"\n",
    "\n",
    "<a href = \"http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\" style = \"float: right\">-Choosing the Right Estimator from sklearn docs</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>An estimator for recognizing a new iris from its measurements</b>\n",
    "\n",
    "> Or, in machine learning parlance, we <i>fit</i> an estimator on known samples of the iris measurements to <i>predict</i> the class to which an unseen iris belongs.\n",
    "\n",
    "Let's give it a try!  (We are actually going to hold out a small percentage of the `iris` dataset and check our predictions against the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Let's load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# split data into training and test sets using the handy train_test_split func\n",
    "# in this split, we are \"holding out\" only one value and label (placed into X_test and y_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try a decision tree classification method\n",
    "from sklearn import tree\n",
    "\n",
    "tree = tree.DecisionTreeClassifier(max_depth = 4,\n",
    "                                criterion = 'entropy', \n",
    "                                class_weight = 'balanced',\n",
    "                                  random_state = 2)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What was the label associated with this test sample? (\"held out\" sample's original label)\n",
    "# Let's predict on our \"held out\" sample\n",
    "y_pred = tree.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#  fill in the blank below\n",
    "\n",
    "# how did our prediction do for first sample in test dataset?\n",
    "print(\"Prediction: %d, Original label: %d\" % (y_pred[0], ___)) # <-- fill in blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's a nifty way to cross-validate (useful for model evaluation!)\n",
    "from sklearn import cross_validation\n",
    "score = cross_validation.cross_val_score(tree, X, y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE:  enter in your own iris data point and see what the prediction is (what limitation do you think you might encounter here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the graph look like for this decision tree?\n",
    "* Note:  You need both Graphviz app and the python wrapper `graphviz`\n",
    "* To install both on OS X:\n",
    "```\n",
    "sudo port install graphviz\n",
    "sudo pip install graphviz\n",
    "```\n",
    "* For general Installation see [this guide](http://graphviz.readthedocs.org/en/latest/manual.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "export_graphviz(tree, out_file=\"mytree.dot\",  \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "\n",
    "with open(\"mytree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph, format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Decision Tree to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(max_depth=4,\n",
    "                                criterion = 'entropy', \n",
    "                                n_estimators = 100, \n",
    "                                class_weight = 'balanced',\n",
    "                                n_jobs = -1,\n",
    "                               random_state = 2)\n",
    "#forest = RandomForestClassifier()\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "y_preds = iris.target_names[forest.predict(X_test)]\n",
    "\n",
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's a nifty way to cross-validate (useful for model evaluation!)\n",
    "from sklearn import cross_validation\n",
    "score = cross_validation.cross_val_score(forest, X, y)\n",
    "score\n",
    "\n",
    "# try running this cell several times - what's happening and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test set vs. cross-validation (Bonus material)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can be explicit and use the `train_test_split` method in scikit-learn ( [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) ) as in (and as shown above for `iris` data):<p>\n",
    "\n",
    "```python\n",
    "# Create some data by hand and place 70% into a training set and the rest into a test set\n",
    "# Here we are using labeled features (X - feature data, y - labels) in our made-up data\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "Be more concise and\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, linear_model\n",
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "clf = linear_model.LinearRegression()\n",
    "score = cross_validation.cross_val_score(clf, X, y)\n",
    "```\n",
    "\n",
    "<p>There is also a `cross_val_predict` method to create estimates rather than scores and is very useful for cross-validation to evaluate models ( [cross_val_predict](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_predict.html) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
