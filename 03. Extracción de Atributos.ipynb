{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (Limpieza) y Transformación de Datos\n",
    "<img src='imgs/fancy_process.png' alt=\"Smiley face\" width=\"700\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se puede facilitar el proceso de aprendizaje por medio de seleccion, creación o reducción de atributos\n",
    "* SelectKBest\n",
    "* PCA\n",
    "* One-Hot Encoder\n",
    "\n",
    "Recordemos los atributos disponibles en el dataset de iris:\n",
    "![Iris with labels](imgs/iris_with_labels.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports for python 2/3 compatibility\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# For python 2, comment these out:\n",
    "# from builtins import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar los mejores K atributos (también reducción de dimensiones)\n",
    "* Esto se considera aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest para seleccionar los mejores atributos\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Nuestros datos limpios (no siempre va a ser tan fácil)\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print('Tamaño Original:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar un nuevo atributo: La proporción entre las medidas del iris\n",
    "df = pd.DataFrame(X, columns = iris.feature_names)\n",
    "df['petal width / sepal width'] = df['petal width (cm)'] / df['sepal width (cm)']\n",
    "new_feature_names = df.columns\n",
    "print('New feature names:', list(new_feature_names))\n",
    "\n",
    "# Hemos agregado un nuevo atributo a los datos\n",
    "X = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seleccion de Atributos:\n",
    "#  la entrada es una función de scoring (acá chi2) que obtienen valores P univariate\n",
    "#  y el número de los K atributos con mejor score, acá elegimos 3\n",
    "dim_red = SelectKBest(chi2, k = 3)\n",
    "dim_red.fit(X, y)\n",
    "X_t = dim_red.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los scores, atributos seleccionados y nuevo shape\n",
    "print('Scores:', dim_red.scores_)\n",
    "print('New shape:', X_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener columnas seleccionadas\n",
    "selected = dim_red.get_support() # Valores booleanos\n",
    "selected_names = new_feature_names[selected]\n",
    "\n",
    "print('Mejores k atributos: ', list(selected_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota acerca de la función de scoring en transformaciones con  `SelectKBest`:**\n",
    "* Para regresión - [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "* Para classificación - [chi2](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2), [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Componente Principal (aka PCA)\n",
    "* Reduce dimensiones (número de atributos), basándose en que información explica la mayor varianza.\n",
    "* Se considera aprendizaje no supervisado\n",
    "* Es útil cuando se tiene un espacio de atributos muy grande (por ejemplo, si el encargado del dataset hubiese hecho 100 medidas de las flores)\n",
    "* Más acerca de PCA en Wikipedia [acá](https://en.wikipedia.org/wiki/Principal_component_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para reducción de dimensiones\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Ejecutar principal component analysis\n",
    "pca = decomposition.PCA(.95)\n",
    "pca.fit(X)\n",
    "X_t = pca.transform(X)\n",
    "(X_t[:, 0])\n",
    "\n",
    "# Importar numpy and matplotlib para visualización\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Separamos los datos basándonos en los primeros dos componentes principales\n",
    "x1, x2 = X_t[:, 0], X_t[:, 1]\n",
    "\n",
    "\n",
    "#  (nota: los nombres de iris pueden conseguirse de iris.target_names, también en docs)\n",
    "c1 = np.array(list('rbg')) # colors\n",
    "colors = c1[y] # y definido por color\n",
    "classes = iris.target_names[y] # y definido por nombre de iris\n",
    "for (i, cla) in enumerate(set(classes)):\n",
    "    xc = [p for (j, p) in enumerate(x1) if classes[j] == cla]\n",
    "    yc = [p for (j, p) in enumerate(x2) if classes[j] == cla]\n",
    "    cols = [c for (j, c) in enumerate(colors) if classes[j] == cla]\n",
    "    plt.scatter(xc, yc, c = cols, label = cla)\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más métodos de selección de atributos [acá](http://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "* It's an operation on feature labels - a method of dummying variable\n",
    "* Expands the feature space by nature of transform - later this can be processed further with a dimensionality reduction (the dummied variables are now their own features)\n",
    "* FYI:  One hot encoding variables is needed for python ML module `tenorflow`\n",
    "* Can do this with `pandas` method or a `sklearn` one-hot-encoder system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pandas` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables with pandas built-in function\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Convert to dataframe and add a column with actual iris species name\n",
    "data = pd.DataFrame(X, columns = iris.feature_names)\n",
    "data['target_name'] = iris.target_names[y]\n",
    "\n",
    "df = pd.get_dummies(data, prefix = ['target_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sklearn` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder for dummying variables\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# We encode both our categorical variable and it's labels\n",
    "enc = OneHotEncoder()\n",
    "label_enc = LabelEncoder() # remember the labels here\n",
    "\n",
    "# Encode labels (can use for discrete numerical values as well)\n",
    "data_label_encoded = label_enc.fit_transform(y)\n",
    "\n",
    "# Encode and \"dummy\" variables\n",
    "data_feature_one_hot_encoded = enc.fit_transform(y.reshape(-1, 1))\n",
    "print(data_feature_one_hot_encoded.shape)\n",
    "\n",
    "num_dummies = data_feature_one_hot_encoded.shape[1]\n",
    "df = pd.DataFrame(data_feature_one_hot_encoded.toarray(), columns = label_enc.inverse_transform(range(num_dummies)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by a Microsoft Employee.\n",
    "\t\n",
    "The MIT License (MIT)<br>\n",
    "Copyright (c) 2016 Micheleen Harris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
