{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for best parameters and create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy reading...create and use a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can add `tensorflow` models to a sklearn pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Pipelining</b> (as an aside to this section)\n",
    "* `Pipeline(steps=[...])` - where steps can be a list of processes through which to put data or a dictionary which includes the parameters for each step as values\n",
    "* For example, here we do a transformation (SelectKBest) and a classification (SVC) all at once in a pipeline we set up.\n",
    "\n",
    "See a full example [here](http://scikit-learn.org/stable/auto_examples/feature_stacker.html)\n",
    "\n",
    "Note:  If you wish to perform <b>multiple transformations</b> in your pipeline try [FeatureUnion](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# a feature selection instance\n",
    "selection = SelectKBest(chi2, k = 2)\n",
    "\n",
    "# classification instance\n",
    "clf = SVC(kernel = 'linear')\n",
    "\n",
    "# make a pipeline\n",
    "pipeline = Pipeline([(\"feature selection\", selection), (\"classification\", clf)])\n",
    "\n",
    "# train the model\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fit(X_train, y_train, X_test, y_pred):\n",
    "    plt.plot(X_test, y_pred, label = \"Model\")\n",
    "    #plt.plot(X_test, fun, label = \"Function\")\n",
    "    plt.scatter(X_train, y_train, label = \"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "#plot_fit(X_train, y_train, X_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last, but not least, Searching Parameter Space with `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "lm = LinearRegression()\n",
    "\n",
    "pipeline = Pipeline([(\"polynomial_features\", poly),\n",
    "                         (\"linear_regression\", lm)])\n",
    "\n",
    "param_grid = dict(polynomial_features__degree = list(range(1, 30, 2)),\n",
    "                  linear_regression__normalize = [False, True])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid)\n",
    "grid_search.fit(X[:, np.newaxis], y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some References\n",
    "* [The iris dataset and an intro to sklearn explained on the Kaggle blog](http://blog.kaggle.com/2015/04/22/scikit-learn-video-3-machine-learning-first-steps-with-the-iris-dataset/)\n",
    "* [A. Mueller's Conference Notebooks and Presentation](https://github.com/amueller/odscon-sf-2015)\n",
    "* [Katie Malone's real-world example set of notebooks for learning ML](https://github.com/cmmalone/malone_OpenDataSciCon)\n",
    "* [Jake VanDerplas's PyCon Scikit-learn youtube video](https://www.youtube.com/watch?v=L7R4HUQ-eQ0)\n",
    "* [Brandon Rohrer's webinar Data Science for the Rest of Us](https://channel9.msdn.com/blogs/Cloud-and-Enterprise-Premium/Data-Science-for-Rest-of-Us)\n",
    "\n",
    "### Some Datasets\n",
    "* [Machine learning datasets](http://mldata.org/)\n",
    "* [Make your own with sklearn](http://scikit-learn.org/stable/datasets/index.html#sample-generators)\n",
    "* [Kaggle datasets](https://www.kaggle.com/datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
