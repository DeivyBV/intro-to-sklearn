{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (Clean Data) and Transform Data\n",
    "<img src='imgs/ml_process_by_micheleenharris.png' alt=\"Smiley face\" width=\"400\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the learning easier or better  beforehand -  feature reduction/selection/creation\n",
    "* SelectKBest\n",
    "* PCA\n",
    "* One-Hot Encoder\n",
    "\n",
    "Just to remind you, the features of the irises we are dealing with on the flower are:\n",
    "![Iris with labels](imgs/iris_with_labels.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports for python 2/3 compatibility\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# For python 2, comment these out:\n",
    "# from builtins import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting k top scoring features (also dimensionality reduction)\n",
    "* Considered unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SelectKBest for selecting top-scoring features\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Our nice, clean data (it's not always going to be this easy)\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print('Original shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add a NEW feature - a ratio of two of the iris measurements\n",
    "df = pd.DataFrame(X, columns = iris.feature_names)\n",
    "df['petal width / sepal width'] = df['petal width (cm)'] / df['sepal width (cm)']\n",
    "new_feature_names = df.columns\n",
    "print('New feature names:', list(new_feature_names))\n",
    "\n",
    "# We've now added a new column to our data\n",
    "X = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform feature selection\n",
    "#  input is scoring function (here chi2) to get univariate p-values\n",
    "#  and number of top-scoring features (k) - here we get the top 3\n",
    "dim_red = SelectKBest(chi2, k = 3)\n",
    "dim_red.fit(X, y)\n",
    "X_t = dim_red.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show scores, features selected and new shape\n",
    "print('Scores:', dim_red.scores_)\n",
    "print('New shape:', X_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get back the selected columns\n",
    "selected = dim_red.get_support() # boolean values\n",
    "selected_names = new_feature_names[selected]\n",
    "\n",
    "print('Top k features: ', list(selected_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on scoring function selection in `SelectKBest` tranformations:**\n",
    "* For regression - [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "* For classification - [chi2](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2), [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (aka PCA)\n",
    "* Reduces dimensions (number of features), based on what information explains the most variance (or signal)\n",
    "* Considered unsupervised learning\n",
    "* Useful for very large feature space (e.g. say the botanist in charge of the iris dataset measured 100 more parts of the flower and thus there were 104 columns instead of 4)\n",
    "* More about PCA on wikipedia [here](https://en.wikipedia.org/wiki/Principal_component_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA for dimensionality reduction\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# perform principal component analysis\n",
    "pca = decomposition.PCA(.95)\n",
    "pca.fit(X)\n",
    "X_t = pca.transform(X)\n",
    "(X_t[:, 0])\n",
    "\n",
    "# import numpy and matplotlib for plotting (and set some stuff)\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# let's separate out data based on first two principle components\n",
    "x1, x2 = X_t[:, 0], X_t[:, 1]\n",
    "\n",
    "\n",
    "# please don't worry about details of the plotting below \n",
    "#  (note: you can get the iris names below from iris.target_names, also in docs)\n",
    "c1 = np.array(list('rbg')) # colors\n",
    "colors = c1[y] # y coded by color\n",
    "classes = iris.target_names[y] # y coded by iris name\n",
    "for (i, cla) in enumerate(set(classes)):\n",
    "    xc = [p for (j, p) in enumerate(x1) if classes[j] == cla]\n",
    "    yc = [p for (j, p) in enumerate(x2) if classes[j] == cla]\n",
    "    cols = [c for (j, c) in enumerate(colors) if classes[j] == cla]\n",
    "    plt.scatter(xc, yc, c = cols, label = cla)\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More feature selection methods [here](http://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "* It's an operation on feature labels - a method of dummying variable\n",
    "* Expands the feature space by nature of transform - later this can be processed further with a dimensionality reduction (the dummied variables are now their own features)\n",
    "* FYI:  One hot encoding variables is needed for python ML module `tenorflow`\n",
    "* Can do this with `pandas` method or a `sklearn` one-hot-encoder system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pandas` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummy variables with pandas built-in function\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Convert to dataframe and add a column with actual iris species name\n",
    "data = pd.DataFrame(X, columns = iris.feature_names)\n",
    "data['target_name'] = iris.target_names[y]\n",
    "\n",
    "df = pd.get_dummies(data, prefix = ['target_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sklearn` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OneHotEncoder for dummying variables\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# We encode both our categorical variable and it's labels\n",
    "enc = OneHotEncoder()\n",
    "label_enc = LabelEncoder() # remember the labels here\n",
    "\n",
    "# Encode labels (can use for discrete numerical values as well)\n",
    "data_label_encoded = label_enc.fit_transform(y)\n",
    "\n",
    "# Encode and \"dummy\" variables\n",
    "data_feature_one_hot_encoded = enc.fit_transform(y.reshape(-1, 1))\n",
    "print(data_feature_one_hot_encoded.shape)\n",
    "\n",
    "num_dummies = data_feature_one_hot_encoded.shape[1]\n",
    "df = pd.DataFrame(data_feature_one_hot_encoded.toarray(), columns = label_enc.inverse_transform(range(num_dummies)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by a Microsoft Employee.\n",
    "\t\n",
    "The MIT License (MIT)<br>\n",
    "Copyright (c) 2016 Micheleen Harris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
